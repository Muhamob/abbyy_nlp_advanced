# Вопросно-ответная система для задачи подтверждения истинности высказывания

В данном задании необходимо исследовать датасет BoolQ, состоящий из триплетов: вопрос, контекст, ответ. При этом допускается ряд допущений:
	1. Вопросы подразумевают собой ответы Да/Нет.
	2. Ответ на вопрос содержится в контексте.
	3. 96% вопросов начинается из набора специальных слов (9 слов).
Несмотря на кажущуюся простоту задачи, простые классификаторы, такие как FastText+Logistic Regression показывают себя не лучше, чем так называемые DummyClassifier.

## FastText + LogisticRegression

#### FastText
```
model: wiki.en.300d
```

#### Logistic Regression
```
solver: liblinear
max_iter: 500
```
#### Результаты
```
              precision    recall  f1-score   support

       False       0.50      0.30      0.38      1237
        True       0.66      0.81      0.73      2033

    accuracy                           0.62      3270
   macro avg       0.58      0.56      0.55      3270
weighted avg       0.60      0.62      0.60      3270
```
#### Выводы
Как видно из метрики, точность ответов не отличается от точности при случайном угадывании

## BERT features + Logistic Regression
### Модели
#### BERT
Модель использовалась для извлечения признаков токенов вопроса и контекста. 
Модель была взята из библиотеки Transformers. 
Вектор текста - осреднение векторов токенов.
Признаки вопроса и контекста затем конкатенировались.
```
model: bert-base-uncased
sentence_vector: avg(model(tokens))
```
#### Logistic Regression
```
solver: liblinear
max_iter: 500
```
####
#### Результаты
```
              precision    recall  f1-score   support

       False       0.57      0.47      0.52      1237
        True       0.71      0.78      0.74      2033

    accuracy                           0.67      3270
   macro avg       0.64      0.63      0.63      3270
weighted avg       0.66      0.67      0.66      3270
```
#### Выводы
В отличии от предудущей модели, данная модель отвечает на вопросы на 5% лучше.
## DrQA:
Данная архитектура изначально создавалась для поиска спана ответа в некотором абзаце. Однако, её можно адаптировать под данную задачу путём отброса слоёв, отвечающих за поиск начала и конца ответа, и заменив её на классификатор.

#### checklist
	[x] Предложить надстройку для данной задачи
	[x] Реализовать / переделать существующие решения
	[x] Настроить пути / датасеты / параметры / метрики
	[x] Получить результаты
	[x] Настроить гиперпараметры

#### Архитектура
х Здесь может быть ваша картинка с архитектурой ъ

#### Результаты
##### Accuracy
```
- model:
    doc layers: 2
    question layers: 2
    hidden size: 64
    grad clipping: 3
  best_accuracy: 0.6889
- model:
    doc layers: 3
    question layers: 3
    hidden size: 64
    grad clipping: 3
  best_accuracy: 0.6923 
```
#### Выводы
Модель показала себя немногим лучше, чем предыдущая

## BiDAF

Архитектура, аналогично предыдущей создавалсь для поиска спанов ответа в контексте. Однако заменив часть с поиском спанов, на слои для задачи бинарной классификации, можно применить архитектуру к данному датасету

#### checklist
	[x] Предложить надстройку для данной задачи
	[] Реализовать / переделать существующие решения
	[] Настроить пути / датасеты / параметры / метрики
	[] Получить результаты
	[] Настроить гиперпараметры

#### Архитектура
х Здесь может быть ваша картинка с архитектурой ъ

#### Результаты
##### Accuracy
х Здесь могут быть ваши результаты с несколькими прогонами при различных параметрах ъ
