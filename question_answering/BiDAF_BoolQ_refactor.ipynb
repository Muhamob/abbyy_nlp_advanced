{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "gXNLBviGNpuj",
    "outputId": "b4e2468a-33cc-4868-b6d3-1ac40cb90526"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/gdrive\n",
      "Cloning into 'BiDAF-pytorch'...\n",
      "remote: Enumerating objects: 55, done.\u001b[K\n",
      "remote: Counting objects: 100% (55/55), done.\u001b[K\n",
      "remote: Compressing objects: 100% (41/41), done.\u001b[K\n",
      "remote: Total 146 (delta 30), reused 31 (delta 13), pack-reused 91\u001b[K\n",
      "Receiving objects: 100% (146/146), 8.67 MiB | 16.90 MiB/s, done.\n",
      "Resolving deltas: 100% (71/71), done.\n",
      "/content/BiDAF-pytorch\n",
      "Branch 'boolq' set up to track remote branch 'boolq' from 'origin'.\n",
      "Switched to a new branch 'boolq'\n",
      "Collecting torch==0.4.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/69/43/380514bd9663f1bf708abeb359b8b48d3fabb1c8e95bb3427a980a064c57/torch-0.4.0-cp36-cp36m-manylinux1_x86_64.whl (484.0MB)\n",
      "\u001b[K     |████████████████████████████████| 484.0MB 31kB/s \n",
      "\u001b[?25hCollecting nltk==3.4.5\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f6/1d/d925cfb4f324ede997f6d47bea4d9babba51b49e87a767c170b77005889d/nltk-3.4.5.zip (1.5MB)\n",
      "\u001b[K     |████████████████████████████████| 1.5MB 40.0MB/s \n",
      "\u001b[?25hCollecting tensorboardX==0.8\n",
      "  Downloading https://files.pythonhosted.org/packages/15/ef/bc8ca04d56332d277b902b8d74a68759419f6e1e0dfef61630afab1785e9/tensorboardX-0.8-py2.py3-none-any.whl\n",
      "Collecting torchtext==0.2.3\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/78/90/474d5944d43001a6e72b9aaed5c3e4f77516fbef2317002da2096fd8b5ea/torchtext-0.2.3.tar.gz (42kB)\n",
      "\u001b[K     |████████████████████████████████| 51kB 6.7MB/s \n",
      "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk==3.4.5->-r requirements.txt (line 2)) (1.12.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tensorboardX==0.8->-r requirements.txt (line 3)) (1.18.4)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from tensorboardX==0.8->-r requirements.txt (line 3)) (3.10.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from torchtext==0.2.3->-r requirements.txt (line 4)) (4.41.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from torchtext==0.2.3->-r requirements.txt (line 4)) (2.23.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->tensorboardX==0.8->-r requirements.txt (line 3)) (46.1.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.2.3->-r requirements.txt (line 4)) (2.9)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.2.3->-r requirements.txt (line 4)) (1.24.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.2.3->-r requirements.txt (line 4)) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.2.3->-r requirements.txt (line 4)) (2020.4.5.1)\n",
      "Building wheels for collected packages: nltk, torchtext\n",
      "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for nltk: filename=nltk-3.4.5-cp36-none-any.whl size=1449904 sha256=577bcb9ccafc641617e7655e70c158af49dd79378f96a74f7ba23653f47a24c1\n",
      "  Stored in directory: /root/.cache/pip/wheels/96/86/f6/68ab24c23f207c0077381a5e3904b2815136b879538a24b483\n",
      "  Building wheel for torchtext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for torchtext: filename=torchtext-0.2.3-cp36-none-any.whl size=40134 sha256=f648113b8871d836878df1f787c8dc729d71e081b12977dcbcd2d13d4d6c2cee\n",
      "  Stored in directory: /root/.cache/pip/wheels/42/a6/f4/b267328bde6bb680094a0c173e8e5627ccc99543abded97204\n",
      "Successfully built nltk torchtext\n",
      "\u001b[31mERROR: torchvision 0.6.0+cu101 has requirement torch==1.5.0, but you'll have torch 0.4.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: fastai 1.0.61 has requirement torch>=1.0.0, but you'll have torch 0.4.0 which is incompatible.\u001b[0m\n",
      "Installing collected packages: torch, nltk, tensorboardX, torchtext\n",
      "  Found existing installation: torch 1.5.0+cu101\n",
      "    Uninstalling torch-1.5.0+cu101:\n",
      "      Successfully uninstalled torch-1.5.0+cu101\n",
      "  Found existing installation: nltk 3.2.5\n",
      "    Uninstalling nltk-3.2.5:\n",
      "      Successfully uninstalled nltk-3.2.5\n",
      "  Found existing installation: torchtext 0.3.1\n",
      "    Uninstalling torchtext-0.3.1:\n",
      "      Successfully uninstalled torchtext-0.3.1\n",
      "Successfully installed nltk-3.4.5 tensorboardX-0.8 torch-0.4.0 torchtext-0.2.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 8572\n",
      "drwxr-xr-x 2 root root    4096 May 11 14:31 .\n",
      "drwxr-xr-x 4 root root    4096 May 11 14:31 ..\n",
      "-rw------- 1 root root 2238726 May 11 14:29 dev.jsonl\n",
      "-rw------- 1 root root 6525813 May 11 14:29 train.jsonl\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')\n",
    "\n",
    "# load dataset\n",
    "!cp /content/gdrive/My\\ Drive/abbyy-nlp/train.jsonl /content\n",
    "!cp /content/gdrive/My\\ Drive/abbyy-nlp/dev.jsonl /content\n",
    "\n",
    "!git clone https://github.com/Muhamob/BiDAF-pytorch.git\n",
    "%cd BiDAF-pytorch\n",
    "!git fetch\n",
    "!git checkout boolq\n",
    "!pip install -r requirements.txt\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "!mkdir .data/boolq\n",
    "!mv /content/*.jsonl .data/boolq\n",
    "!ls -la .data/boolq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NgzGzfk6Six3"
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "x1dvrpF6S5rX",
    "outputId": "9f66ad90-44d6-4baf-b51e-5909174c0485"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"question\": \"does ethanol take more energy make that produces\", \"title\": \"Ethanol fuel\", \"answer\": false, \"passage\": \"All biomass goes through at least some of these steps: it needs to be grown, collected, dried, fermented, distilled, and burned. All of these steps require resources and an infrastructure. The total amount of energy input into the process compared to the energy released by burning the resulting ethanol fuel is known as the energy balance (or ``energy returned on energy invested''). Figures compiled in a 2007 report by National Geographic Magazine point to modest results for corn ethanol produced in the US: one unit of fossil-fuel energy is required to create 1.3 energy units from the resulting ethanol. The energy balance for sugarcane ethanol produced in Brazil is more favorable, with one unit of fossil-fuel energy required to create 8 from the ethanol. Energy balance estimates are not easily produced, thus numerous such reports have been generated that are contradictory. For instance, a separate survey reports that production of ethanol from sugarcane, which requires a tropical climate to grow productively, returns from 8 to 9 units of energy for each unit expended, as compared to corn, which only returns about 1.34 units of fuel energy for each unit of energy expended. A 2006 University of California Berkeley study, after analyzing six separate studies, concluded that producing ethanol from corn uses much less petroleum than producing gasoline.\"}\n"
     ]
    }
   ],
   "source": [
    "!head .data/boolq/dev.jsonl -n 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t5-RdIdhShYd"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import nltk\n",
    "import torch\n",
    "\n",
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "from torchtext.vocab import GloVe\n",
    "\n",
    "\n",
    "def word_tokenize(tokens):\n",
    "    return [token.replace(\"''\", '\"').replace(\"``\", '\"') for token in nltk.word_tokenize(tokens)]\n",
    "\n",
    "\n",
    "class BoolQ():\n",
    "    def __init__(self, \n",
    "                 word_dim: int, \n",
    "                 train_batch_size: int, \n",
    "                 dev_batch_size: int, \n",
    "                 context_threshold: int = 0,\n",
    "                 gpu: int = 0):\n",
    "        path = '.data/boolq'\n",
    "        dataset_path = path + '/torchtext/'\n",
    "        train_examples_path = dataset_path + 'train_examples.pt'\n",
    "        dev_examples_path = dataset_path + 'dev_examples.pt'\n",
    "\n",
    "        self.RAW = data.RawField()\n",
    "        # explicit declaration for torchtext compatibility\n",
    "        self.RAW.is_target = False\n",
    "        self.CHAR_NESTING = data.Field(batch_first=True, tokenize=list, lower=True)\n",
    "        self.CHAR = data.NestedField(self.CHAR_NESTING, tokenize=word_tokenize)\n",
    "        self.WORD = data.Field(batch_first=True, tokenize=word_tokenize, lower=True, include_lengths=True)\n",
    "        self.LABEL = data.Field(sequential=False, unk_token=None, use_vocab=False)\n",
    "\n",
    "        dict_fields = {'answer': ('answer', self.LABEL),\n",
    "                       'passage': [('c_word', self.WORD), ('c_char', self.CHAR)],\n",
    "                       'question': [('q_word', self.WORD), ('q_char', self.CHAR)]}\n",
    "\n",
    "        list_fields = [('answer', self.LABEL),\n",
    "                       ('c_word', self.WORD), ('c_char', self.CHAR),\n",
    "                       ('q_word', self.WORD), ('q_char', self.CHAR)]\n",
    "\n",
    "        if os.path.exists(dataset_path):\n",
    "            print(\"loading splits...\")\n",
    "            train_examples = torch.load(train_examples_path)\n",
    "            dev_examples = torch.load(dev_examples_path)\n",
    "\n",
    "            self.train = data.Dataset(examples=train_examples, fields=list_fields)\n",
    "            self.dev = data.Dataset(examples=dev_examples, fields=list_fields)\n",
    "        else:\n",
    "            print(\"building splits...\")\n",
    "            self.train, self.dev = data.TabularDataset.splits(\n",
    "                path=path,\n",
    "                train='train.jsonl',\n",
    "                validation='dev.jsonl',\n",
    "                format='json',\n",
    "                fields=dict_fields)\n",
    "\n",
    "            os.makedirs(dataset_path)\n",
    "            torch.save(self.train.examples, train_examples_path)\n",
    "            torch.save(self.dev.examples, dev_examples_path)\n",
    "\n",
    "        #cut too long context in the training set for efficiency.\n",
    "        if context_threshold > 0:\n",
    "            self.train.examples = [e for e in self.train.examples if len(e.c_word) <= context_threshold]\n",
    "\n",
    "        print(\"building vocab...\")\n",
    "        self.CHAR.build_vocab(self.train, self.dev)\n",
    "        self.WORD.build_vocab(self.train, self.dev, vectors=GloVe(name='6B', dim=word_dim))\n",
    "\n",
    "        print(\"building iterators...\")\n",
    "        device = torch.device(\"cuda:{}\".format(gpu) if torch.cuda.is_available() else \"cpu\")\n",
    "        print(device)\n",
    "        self.train_iter = data.BucketIterator(\n",
    "            self.train,\n",
    "            batch_size=train_batch_size,\n",
    "            device=device,\n",
    "            repeat=True,\n",
    "            shuffle=True,\n",
    "            sort_key=lambda x: len(x.c_word)\n",
    "        )\n",
    "\n",
    "        self.dev_iter = data.BucketIterator(\n",
    "            self.dev,\n",
    "            batch_size=dev_batch_size,\n",
    "            device=device,\n",
    "            repeat=False,\n",
    "            sort_key=lambda x: len(x.c_word)\n",
    "        )\n",
    "\n",
    "    def preprocess_file(self, path):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "rF1nZ6OYVWcm",
    "outputId": "d69f24e1-0592-4b83-fa73-c9c673212620"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already up to date.\n",
      "loading splits...\n",
      "building vocab...\n",
      "building iterators...\n",
      "cuda:0\n",
      "epoch: 1\n",
      "Количество ответов с меткой True 3270\n",
      "train loss: 168.161 / dev loss: 68.923 /  dev accuracy: 0.622\n",
      "epoch: 2\n",
      "Количество ответов с меткой True 3270\n",
      "train loss: 166.135 / dev loss: 68.770 /  dev accuracy: 0.622\n",
      "epoch: 3\n",
      "Количество ответов с меткой True 3270\n",
      "train loss: 166.089 / dev loss: 68.670 /  dev accuracy: 0.622\n",
      "epoch: 4\n",
      "Количество ответов с меткой True 3270\n",
      "train loss: 163.489 / dev loss: 68.286 /  dev accuracy: 0.622\n",
      "epoch: 5\n",
      "Количество ответов с меткой True 3270\n",
      "train loss: 160.253 / dev loss: 67.914 /  dev accuracy: 0.622\n",
      "epoch: 6\n",
      "Количество ответов с меткой True 3270\n",
      "train loss: 157.381 / dev loss: 67.420 /  dev accuracy: 0.622\n",
      "Количество ответов с меткой True 3265\n",
      "train loss: 155.485 / dev loss: 66.742 /  dev accuracy: 0.621\n",
      "epoch: 7\n",
      "Количество ответов с меткой True 3222\n",
      "train loss: 150.048 / dev loss: 66.381 /  dev accuracy: 0.626\n",
      "epoch: 8\n",
      "Количество ответов с меткой True 3062\n",
      "train loss: 148.110 / dev loss: 65.747 /  dev accuracy: 0.635\n",
      "epoch: 9\n",
      "Количество ответов с меткой True 2948\n",
      "train loss: 142.911 / dev loss: 65.432 /  dev accuracy: 0.644\n",
      "epoch: 10\n",
      "Количество ответов с меткой True 2795\n",
      "train loss: 137.513 / dev loss: 64.776 /  dev accuracy: 0.655\n",
      "epoch: 11\n",
      "Количество ответов с меткой True 2684\n",
      "train loss: 131.309 / dev loss: 65.479 /  dev accuracy: 0.654\n",
      "epoch: 12\n",
      "Количество ответов с меткой True 2582\n",
      "train loss: 130.050 / dev loss: 65.161 /  dev accuracy: 0.655\n",
      "Количество ответов с меткой True 2505\n",
      "train loss: 120.404 / dev loss: 65.818 /  dev accuracy: 0.661\n",
      "epoch: 13\n",
      "Количество ответов с меткой True 2441\n",
      "train loss: 116.510 / dev loss: 67.148 /  dev accuracy: 0.658\n",
      "epoch: 14\n",
      "Количество ответов с меткой True 2388\n",
      "train loss: 107.970 / dev loss: 67.748 /  dev accuracy: 0.661\n",
      "epoch: 15\n",
      "Количество ответов с меткой True 2349\n",
      "train loss: 103.176 / dev loss: 69.631 /  dev accuracy: 0.661\n",
      "epoch: 16\n",
      "Количество ответов с меткой True 2304\n",
      "train loss: 97.898 / dev loss: 70.636 /  dev accuracy: 0.662\n",
      "epoch: 17\n",
      "Количество ответов с меткой True 2267\n",
      "train loss: 91.565 / dev loss: 72.755 /  dev accuracy: 0.661\n"
     ]
    }
   ],
   "source": [
    "!git pull\n",
    "!rm -rf runs/\n",
    "from time import gmtime, strftime\n",
    "from importlib import reload \n",
    "import run\n",
    "reload(run)\n",
    "\n",
    "dataset = BoolQ(word_dim=100, train_batch_size=32, dev_batch_size=32)\n",
    "\n",
    "config = {\n",
    "    'char_dim': 8,\n",
    "    'char_channel_width': 5,\n",
    "    'char_channel_size': 100,\n",
    "    'context_threshold': 0,\n",
    "    'dev_batch_size': 100,\n",
    "    'dropout': 0.1,\n",
    "    'epoch': 25,\n",
    "    'exp_decay_rate': 0.999,\n",
    "    'gpu': 0,\n",
    "    'hidden_size': 100,\n",
    "    'learning_rate': 0.5,\n",
    "    'grad_clipping': 3,\n",
    "    'weight_decay': 0,\n",
    "    'print_freq': 250,\n",
    "    'train_batch_size': 32,\n",
    "    'word_dim': 100,\n",
    "    'char_vocab_size': len(dataset.CHAR.vocab),\n",
    "    'word_vocab_size': len(dataset.WORD.vocab),\n",
    "    'model_time': strftime('%H:%M:%S', gmtime())\n",
    "}\n",
    "\n",
    "class Config:\n",
    "    def __init__(self, d):\n",
    "        for key, value in d.items():\n",
    "            setattr(self, key, value)\n",
    "\n",
    "args = Config(config)\n",
    "run.train(args, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XIfBhbDLktc1"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "BiDAF_BoolQ_refactor.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
