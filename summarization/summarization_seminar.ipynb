{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "summarization_seminar.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "OqkLTkFRfXvA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ed3e2e11-ebb7-4f48-8465-c0250b02222c"
      },
      "source": [
        "!wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.ru.300.bin.gz\n",
        "!wget https://www.dropbox.com/s/43l702z5a5i2w8j/gazeta_train.txt\n",
        "!wget https://www.dropbox.com/s/k2egt3sug0hb185/gazeta_val.txt\n",
        "!wget https://www.dropbox.com/s/3gki5n5djs9w0v6/gazeta_test.txt"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-05-06 21:39:16--  https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.ru.300.bin.gz\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.22.74.142, 104.22.75.142, 2606:4700:10::6816:4b8e, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.22.74.142|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4496459151 (4.2G) [application/octet-stream]\n",
            "Saving to: ‘cc.ru.300.bin.gz’\n",
            "\n",
            "cc.ru.300.bin.gz    100%[===================>]   4.19G  22.3MB/s    in 3m 13s  \n",
            "\n",
            "2020-05-06 21:42:30 (22.2 MB/s) - ‘cc.ru.300.bin.gz’ saved [4496459151/4496459151]\n",
            "\n",
            "--2020-05-06 21:42:31--  https://www.dropbox.com/s/43l702z5a5i2w8j/gazeta_train.txt\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.9.1, 2620:100:601f:1::a27d:901\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.9.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/43l702z5a5i2w8j/gazeta_train.txt [following]\n",
            "--2020-05-06 21:42:31--  https://www.dropbox.com/s/raw/43l702z5a5i2w8j/gazeta_train.txt\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc95bfc2c79fcf8d312080aab6f1.dl.dropboxusercontent.com/cd/0/inline/A3PYu6IuG1QQC4glXR1AD-HjpULqE1eZ5GRVscnsErGBinYZDc2pBQ_NQjBNYHmj4SLMD263GDZLmrFMF8LytoccfT5EzcXwNjhLadTYYw1veFy_-MsC65OJzLYqDec-IjU/file# [following]\n",
            "--2020-05-06 21:42:31--  https://uc95bfc2c79fcf8d312080aab6f1.dl.dropboxusercontent.com/cd/0/inline/A3PYu6IuG1QQC4glXR1AD-HjpULqE1eZ5GRVscnsErGBinYZDc2pBQ_NQjBNYHmj4SLMD263GDZLmrFMF8LytoccfT5EzcXwNjhLadTYYw1veFy_-MsC65OJzLYqDec-IjU/file\n",
            "Resolving uc95bfc2c79fcf8d312080aab6f1.dl.dropboxusercontent.com (uc95bfc2c79fcf8d312080aab6f1.dl.dropboxusercontent.com)... 162.125.9.6, 2620:100:601f:6::a27d:906\n",
            "Connecting to uc95bfc2c79fcf8d312080aab6f1.dl.dropboxusercontent.com (uc95bfc2c79fcf8d312080aab6f1.dl.dropboxusercontent.com)|162.125.9.6|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 470816510 (449M) [text/plain]\n",
            "Saving to: ‘gazeta_train.txt.3’\n",
            "\n",
            "gazeta_train.txt.3  100%[===================>] 449.00M  38.7MB/s    in 12s     \n",
            "\n",
            "2020-05-06 21:42:44 (38.0 MB/s) - ‘gazeta_train.txt.3’ saved [470816510/470816510]\n",
            "\n",
            "--2020-05-06 21:42:45--  https://www.dropbox.com/s/k2egt3sug0hb185/gazeta_val.txt\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.9.1, 2620:100:601f:1::a27d:901\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.9.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/k2egt3sug0hb185/gazeta_val.txt [following]\n",
            "--2020-05-06 21:42:45--  https://www.dropbox.com/s/raw/k2egt3sug0hb185/gazeta_val.txt\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc09e95750ea554d570dc724af8f.dl.dropboxusercontent.com/cd/0/inline/A3OdH9MVa4aDyAGPoYtfLc6sr5bAzFEZqMmlCKtiuq2oaG-vM4-yum8KLbMHBhK3QDUwNG9r_Fp123WJwFJeV3XdqSHI1MXUbpWIerV7m4l-rG8DYVwLQoJXxstXLuYXArg/file# [following]\n",
            "--2020-05-06 21:42:45--  https://uc09e95750ea554d570dc724af8f.dl.dropboxusercontent.com/cd/0/inline/A3OdH9MVa4aDyAGPoYtfLc6sr5bAzFEZqMmlCKtiuq2oaG-vM4-yum8KLbMHBhK3QDUwNG9r_Fp123WJwFJeV3XdqSHI1MXUbpWIerV7m4l-rG8DYVwLQoJXxstXLuYXArg/file\n",
            "Resolving uc09e95750ea554d570dc724af8f.dl.dropboxusercontent.com (uc09e95750ea554d570dc724af8f.dl.dropboxusercontent.com)... 162.125.9.6, 2620:100:601f:6::a27d:906\n",
            "Connecting to uc09e95750ea554d570dc724af8f.dl.dropboxusercontent.com (uc09e95750ea554d570dc724af8f.dl.dropboxusercontent.com)|162.125.9.6|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 48626461 (46M) [text/plain]\n",
            "Saving to: ‘gazeta_val.txt.3’\n",
            "\n",
            "gazeta_val.txt.3    100%[===================>]  46.37M  63.8MB/s    in 0.7s    \n",
            "\n",
            "2020-05-06 21:42:46 (63.8 MB/s) - ‘gazeta_val.txt.3’ saved [48626461/48626461]\n",
            "\n",
            "--2020-05-06 21:42:48--  https://www.dropbox.com/s/3gki5n5djs9w0v6/gazeta_test.txt\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.9.1, 2620:100:601b:1::a27d:801\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.9.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/3gki5n5djs9w0v6/gazeta_test.txt [following]\n",
            "--2020-05-06 21:42:48--  https://www.dropbox.com/s/raw/3gki5n5djs9w0v6/gazeta_test.txt\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc989b7aa7564b5d30dfd998cb60.dl.dropboxusercontent.com/cd/0/inline/A3M6NJ2UA2hlXjjvqWWuwgAltZK-yG-cwmlekDvHLAvHUm2Jd9vCmDfQ3jli4ttjDKxZSvn_2Sq8YG36oMnu9t9bg6F3ki8XfsEBTPp7m1pJF3HAsG8JQgTU9Sdf04kIOAI/file# [following]\n",
            "--2020-05-06 21:42:48--  https://uc989b7aa7564b5d30dfd998cb60.dl.dropboxusercontent.com/cd/0/inline/A3M6NJ2UA2hlXjjvqWWuwgAltZK-yG-cwmlekDvHLAvHUm2Jd9vCmDfQ3jli4ttjDKxZSvn_2Sq8YG36oMnu9t9bg6F3ki8XfsEBTPp7m1pJF3HAsG8JQgTU9Sdf04kIOAI/file\n",
            "Resolving uc989b7aa7564b5d30dfd998cb60.dl.dropboxusercontent.com (uc989b7aa7564b5d30dfd998cb60.dl.dropboxusercontent.com)... 162.125.9.6, 2620:100:601f:6::a27d:906\n",
            "Connecting to uc989b7aa7564b5d30dfd998cb60.dl.dropboxusercontent.com (uc989b7aa7564b5d30dfd998cb60.dl.dropboxusercontent.com)|162.125.9.6|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 52142626 (50M) [text/plain]\n",
            "Saving to: ‘gazeta_test.txt.3’\n",
            "\n",
            "gazeta_test.txt.3   100%[===================>]  49.73M  33.0MB/s    in 1.5s    \n",
            "\n",
            "2020-05-06 21:42:50 (33.0 MB/s) - ‘gazeta_test.txt.3’ saved [52142626/52142626]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2e4dabpr6Qh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!gzip -d cc.ru.300.bin.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXS1sdYZCluU",
        "colab_type": "code",
        "outputId": "8c9c47a7-bbdc-4e57-988f-eab839b82022",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install --upgrade razdel allennlp torch fasttext OpenNMT-py networkx pymorphy2 nltk rouge==0.3.1 summa sentencepiece==0.1.8"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting razdel\n",
            "  Downloading https://files.pythonhosted.org/packages/15/2c/664223a3924aa6e70479f7d37220b3a658765b9cfe760b4af7ffdc50d38f/razdel-0.5.0-py3-none-any.whl\n",
            "Collecting allennlp\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/bb/041115d8bad1447080e5d1e30097c95e4b66e36074277afce8620a61cee3/allennlp-0.9.0-py3-none-any.whl (7.6MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6MB 4.3MB/s \n",
            "\u001b[?25hRequirement already up-to-date: torch in /usr/local/lib/python3.6/dist-packages (1.5.0+cu101)\n",
            "Collecting fasttext\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f8/85/e2b368ab6d3528827b147fdb814f8189acc981a4bc2f99ab894650e05c40/fasttext-0.9.2.tar.gz (68kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 9.0MB/s \n",
            "\u001b[?25hCollecting OpenNMT-py\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7e/c7/b3d9bf9a6a681b10c00aa897650f79d4e7ad8a80317c5cddb6a3ef43540c/OpenNMT_py-1.1.1-py3-none-any.whl (189kB)\n",
            "\u001b[K     |████████████████████████████████| 194kB 42.3MB/s \n",
            "\u001b[?25hRequirement already up-to-date: networkx in /usr/local/lib/python3.6/dist-packages (2.4)\n",
            "Collecting pymorphy2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/33/fff9675c68b5f6c63ec8c6e6ff57827dda28a1fa5b2c2d727dffff92dd47/pymorphy2-0.8-py2.py3-none-any.whl (46kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 7.0MB/s \n",
            "\u001b[?25hCollecting nltk\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/92/75/ce35194d8e3022203cca0d2f896dbb88689f9b3fce8e9f9cff942913519d/nltk-3.5.zip (1.4MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4MB 45.2MB/s \n",
            "\u001b[?25hCollecting rouge==0.3.1\n",
            "  Downloading https://files.pythonhosted.org/packages/8f/89/af359c22e1d858e0299d4cc9219f36b504817c9797acad23081247867845/rouge-0.3.1-py3-none-any.whl\n",
            "Collecting summa\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/3b/1c7dc435d05aef474c4137328400f1e11787b9bffab1f87a3f160c1fef54/summa-1.2.0.tar.gz (54kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 8.2MB/s \n",
            "\u001b[?25hCollecting sentencepiece==0.1.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ed/86/aeb647d3ccb924997ea0d05b457d82648a1da57c471688ffbbd69650d9bc/sentencepiece-0.1.8-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 49.0MB/s \n",
            "\u001b[?25hCollecting responses>=0.7\n",
            "  Downloading https://files.pythonhosted.org/packages/01/0c/e4da4191474e27bc41bedab2bf249b27d9261db749f59769d7e7ca8feead/responses-0.10.14-py2.py3-none-any.whl\n",
            "Collecting word2number>=1.1\n",
            "  Downloading https://files.pythonhosted.org/packages/4a/29/a31940c848521f0725f0df6b25dca8917f13a2025b0e8fcbe5d0457e45e6/word2number-1.1.zip\n",
            "Collecting jsonpickle\n",
            "  Downloading https://files.pythonhosted.org/packages/af/ca/4fee219cc4113a5635e348ad951cf8a2e47fed2e3342312493f5b73d0007/jsonpickle-1.4.1-py2.py3-none-any.whl\n",
            "Collecting pytorch-pretrained-bert>=0.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 52.0MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: scikit-learn in /usr/local/lib/python3.6/dist-packages (from allennlp) (0.22.2.post1)\n",
            "Collecting tensorboardX>=1.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/35/f1/5843425495765c8c2dd0784a851a93ef204d314fc87bcc2bbb9f662a3ad1/tensorboardX-2.0-py2.py3-none-any.whl (195kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 55.1MB/s \n",
            "\u001b[?25hCollecting jsonnet>=0.10.0; sys_platform != \"win32\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/33/b8/a8588d4010f13716a324f55d23999259bad9db2320f4fe919a66b2f651f3/jsonnet-0.15.0.tar.gz (255kB)\n",
            "\u001b[K     |████████████████████████████████| 256kB 48.9MB/s \n",
            "\u001b[?25hCollecting flask-cors>=3.0.7\n",
            "  Downloading https://files.pythonhosted.org/packages/78/38/e68b11daa5d613e3a91e4bf3da76c94ac9ee0d9cd515af9c1ab80d36f709/Flask_Cors-3.0.8-py2.py3-none-any.whl\n",
            "Collecting parsimonious>=0.8.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/fc/067a3f89869a41009e1a7cdfb14725f8ddd246f30f63c645e8ef8a1c56f4/parsimonious-0.8.1.tar.gz (45kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 7.4MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: boto3 in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.13.1)\n",
            "Requirement already satisfied, skipping upgrade: requests>=2.18 in /usr/local/lib/python3.6/dist-packages (from allennlp) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: matplotlib>=2.2.3 in /usr/local/lib/python3.6/dist-packages (from allennlp) (3.2.1)\n",
            "Requirement already satisfied, skipping upgrade: editdistance in /usr/local/lib/python3.6/dist-packages (from allennlp) (0.5.3)\n",
            "Collecting unidecode\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/42/d9edfed04228bacea2d824904cae367ee9efd05e6cce7ceaaedd0b0ad964/Unidecode-1.1.1-py2.py3-none-any.whl (238kB)\n",
            "\u001b[K     |████████████████████████████████| 245kB 50.8MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.6/dist-packages (from allennlp) (2.10.0)\n",
            "Collecting overrides\n",
            "  Downloading https://files.pythonhosted.org/packages/72/dd/ac49f9c69540d7e09210415801a05d0a54d4d0ca8401503c46847dacd3a0/overrides-2.8.0.tar.gz\n",
            "Requirement already satisfied, skipping upgrade: pytest in /usr/local/lib/python3.6/dist-packages (from allennlp) (3.6.4)\n",
            "Collecting numpydoc>=0.8.0\n",
            "  Downloading https://files.pythonhosted.org/packages/b0/70/4d8c3f9f6783a57ac9cc7a076e5610c0cc4a96af543cafc9247ac307fbfe/numpydoc-0.9.2.tar.gz\n",
            "Collecting pytorch-transformers==1.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/89/ad0d6bb932d0a51793eaabcf1617a36ff530dc9ab9e38f765a35dc293306/pytorch_transformers-1.1.0-py3-none-any.whl (158kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 49.7MB/s \n",
            "\u001b[?25hCollecting ftfy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ec/d8/5e877ac5e827eaa41a7ea8c0dc1d3042e05d7e337604dc2aedb854e7b500/ftfy-5.7.tar.gz (58kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 8.2MB/s \n",
            "\u001b[?25hCollecting flaky\n",
            "  Downloading https://files.pythonhosted.org/packages/fe/12/0f169abf1aa07c7edef4855cca53703d2e6b7ecbded7829588ac7e7e3424/flaky-3.6.1-py2.py3-none-any.whl\n",
            "Collecting gevent>=1.3.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/bd/04c4036f46f0272c804fce2c8308e06f8fb5db3b5c3adf97f8765bfa502c/gevent-20.5.0-cp36-cp36m-manylinux2010_x86_64.whl (5.2MB)\n",
            "\u001b[K     |████████████████████████████████| 5.2MB 33.7MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: sqlparse>=0.2.4 in /usr/local/lib/python3.6/dist-packages (from allennlp) (0.3.1)\n",
            "Requirement already satisfied, skipping upgrade: flask>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.1.2)\n",
            "Collecting spacy<2.2,>=2.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/41/5b/e07dd3bf104237bce4b398558b104c8e500333d6f30eabe3fa9685356b7d/spacy-2.1.9-cp36-cp36m-manylinux1_x86_64.whl (30.8MB)\n",
            "\u001b[K     |████████████████████████████████| 30.9MB 101kB/s \n",
            "\u001b[?25hCollecting conllu==1.3.1\n",
            "  Downloading https://files.pythonhosted.org/packages/ae/54/b0ae1199f3d01666821b028cd967f7c0ac527ab162af433d3da69242cea2/conllu-1.3.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: tqdm>=4.19 in /usr/local/lib/python3.6/dist-packages (from allennlp) (4.38.0)\n",
            "Requirement already satisfied, skipping upgrade: pytz>=2017.3 in /usr/local/lib/python3.6/dist-packages (from allennlp) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.18.3)\n",
            "Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.6/dist-packages (from allennlp) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: future in /usr/local/lib/python3.6/dist-packages (from torch) (0.16.0)\n",
            "Requirement already satisfied, skipping upgrade: pybind11>=2.2 in /usr/local/lib/python3.6/dist-packages (from fasttext) (2.5.0)\n",
            "Requirement already satisfied, skipping upgrade: setuptools>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from fasttext) (46.1.3)\n",
            "Requirement already satisfied, skipping upgrade: pyyaml in /usr/local/lib/python3.6/dist-packages (from OpenNMT-py) (3.13)\n",
            "Requirement already satisfied, skipping upgrade: tensorboard>=1.14 in /usr/local/lib/python3.6/dist-packages (from OpenNMT-py) (2.2.1)\n",
            "Collecting torchtext==0.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/43/94/929d6bd236a4fb5c435982a7eb9730b78dcd8659acf328fd2ef9de85f483/torchtext-0.4.0-py3-none-any.whl (53kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 8.4MB/s \n",
            "\u001b[?25hCollecting configargparse\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/79/3045743bb26ca2e44a1d317c37395462bfed82dbbd38e69a3280b63696ce/ConfigArgParse-1.2.3.tar.gz (42kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 7.1MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from OpenNMT-py) (1.12.0)\n",
            "Collecting pyonmttok==1.*; platform_system == \"Linux\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/08/20/3c57198ffe690b580fbf23d33d5000eb411862e60e4bb6853b61dc989187/pyonmttok-1.18.3-cp36-cp36m-manylinux1_x86_64.whl (2.2MB)\n",
            "\u001b[K     |████████████████████████████████| 2.2MB 45.9MB/s \n",
            "\u001b[?25hCollecting waitress\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a8/ca/ede3ed29723ca944f6e77bd1d7b38c271dd801c7d6a11ab6037597e4fd5b/waitress-1.4.3-py2.py3-none-any.whl (148kB)\n",
            "\u001b[K     |████████████████████████████████| 153kB 45.6MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx) (4.4.2)\n",
            "Requirement already satisfied, skipping upgrade: docopt>=0.6 in /usr/local/lib/python3.6/dist-packages (from pymorphy2) (0.6.2)\n",
            "Collecting dawg-python>=0.7\n",
            "  Downloading https://files.pythonhosted.org/packages/6a/84/ff1ce2071d4c650ec85745766c0047ccc3b5036f1d03559fd46bb38b5eeb/DAWG_Python-0.7.2-py2.py3-none-any.whl\n",
            "Collecting pymorphy2-dicts<3.0,>=2.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/51/2465fd4f72328ab50877b54777764d928da8cb15b74e2680fc1bd8cb3173/pymorphy2_dicts-2.4.393442.3710985-py2.py3-none-any.whl (7.1MB)\n",
            "\u001b[K     |████████████████████████████████| 7.1MB 32.2MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.6/dist-packages (from nltk) (7.1.2)\n",
            "Requirement already satisfied, skipping upgrade: joblib in /usr/local/lib/python3.6/dist-packages (from nltk) (0.14.1)\n",
            "Requirement already satisfied, skipping upgrade: regex in /usr/local/lib/python3.6/dist-packages (from nltk) (2019.12.20)\n",
            "Requirement already satisfied, skipping upgrade: importlib-metadata in /usr/local/lib/python3.6/dist-packages (from jsonpickle->allennlp) (1.6.0)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX>=1.2->allennlp) (3.10.0)\n",
            "Requirement already satisfied, skipping upgrade: botocore<1.17.0,>=1.16.1 in /usr/local/lib/python3.6/dist-packages (from boto3->allennlp) (1.16.1)\n",
            "Requirement already satisfied, skipping upgrade: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->allennlp) (0.3.3)\n",
            "Requirement already satisfied, skipping upgrade: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->allennlp) (0.9.5)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp) (2.9)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp) (2020.4.5.1)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->allennlp) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->allennlp) (0.10.0)\n",
            "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->allennlp) (1.2.0)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->allennlp) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp) (8.2.0)\n",
            "Requirement already satisfied, skipping upgrade: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp) (1.8.1)\n",
            "Requirement already satisfied, skipping upgrade: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp) (1.4.0)\n",
            "Requirement already satisfied, skipping upgrade: pluggy<0.8,>=0.5 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp) (0.7.1)\n",
            "Requirement already satisfied, skipping upgrade: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp) (19.3.0)\n",
            "Requirement already satisfied, skipping upgrade: sphinx>=1.6.5 in /usr/local/lib/python3.6/dist-packages (from numpydoc>=0.8.0->allennlp) (1.8.5)\n",
            "Requirement already satisfied, skipping upgrade: Jinja2>=2.3 in /usr/local/lib/python3.6/dist-packages (from numpydoc>=0.8.0->allennlp) (2.11.2)\n",
            "Requirement already satisfied, skipping upgrade: wcwidth in /usr/local/lib/python3.6/dist-packages (from ftfy->allennlp) (0.1.9)\n",
            "Collecting greenlet>=0.4.14; platform_python_implementation == \"CPython\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bf/45/142141aa47e01a5779f0fa5a53b81f8379ce8f2b1cd13df7d2f1d751ae42/greenlet-0.4.15-cp36-cp36m-manylinux1_x86_64.whl (41kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.2MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: Werkzeug>=0.15 in /usr/local/lib/python3.6/dist-packages (from flask>=1.0.2->allennlp) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from flask>=1.0.2->allennlp) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.1.0->allennlp) (2.0.3)\n",
            "Collecting thinc<7.1.0,>=7.0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/a5/9ace20422e7bb1bdcad31832ea85c52a09900cd4a7ce711246bfb92206ba/thinc-7.0.8-cp36-cp36m-manylinux1_x86_64.whl (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 48.1MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.1.0->allennlp) (1.0.2)\n",
            "Requirement already satisfied, skipping upgrade: srsly<1.1.0,>=0.0.6 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.1.0->allennlp) (1.0.2)\n",
            "Collecting blis<0.3.0,>=0.2.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/34/46/b1d0bb71d308e820ed30316c5f0a017cb5ef5f4324bcbc7da3cf9d3b075c/blis-0.2.4-cp36-cp36m-manylinux1_x86_64.whl (3.2MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 45.2MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: wasabi<1.1.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.2,>=2.1.0->allennlp) (0.6.0)\n",
            "Collecting preshed<2.1.0,>=2.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/20/93/f222fb957764a283203525ef20e62008675fd0a14ffff8cc1b1490147c63/preshed-2.0.1-cp36-cp36m-manylinux1_x86_64.whl (83kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 11.7MB/s \n",
            "\u001b[?25hCollecting plac<1.0.0,>=0.9.6\n",
            "  Downloading https://files.pythonhosted.org/packages/9e/9b/62c60d2f5bc135d2aa1d8c8a86aaf84edb719a59c7f11a4316259e61a298/plac-0.9.6-py2.py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->OpenNMT-py) (0.34.2)\n",
            "Requirement already satisfied, skipping upgrade: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->OpenNMT-py) (0.9.0)\n",
            "Requirement already satisfied, skipping upgrade: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->OpenNMT-py) (1.6.0.post3)\n",
            "Requirement already satisfied, skipping upgrade: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->OpenNMT-py) (1.7.2)\n",
            "Requirement already satisfied, skipping upgrade: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->OpenNMT-py) (0.4.1)\n",
            "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->OpenNMT-py) (3.2.1)\n",
            "Requirement already satisfied, skipping upgrade: grpcio>=1.24.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=1.14->OpenNMT-py) (1.28.1)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata->jsonpickle->allennlp) (3.1.0)\n",
            "Requirement already satisfied, skipping upgrade: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.17.0,>=1.16.1->boto3->allennlp) (0.15.2)\n",
            "Requirement already satisfied, skipping upgrade: imagesize in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp) (1.2.0)\n",
            "Requirement already satisfied, skipping upgrade: snowballstemmer>=1.1 in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp) (2.0.0)\n",
            "Requirement already satisfied, skipping upgrade: alabaster<0.8,>=0.7 in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp) (0.7.12)\n",
            "Requirement already satisfied, skipping upgrade: Pygments>=2.0 in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp) (2.1.3)\n",
            "Requirement already satisfied, skipping upgrade: sphinxcontrib-websupport in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp) (1.2.2)\n",
            "Requirement already satisfied, skipping upgrade: packaging in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp) (20.3)\n",
            "Requirement already satisfied, skipping upgrade: babel!=2.0,>=1.3 in /usr/local/lib/python3.6/dist-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp) (2.8.0)\n",
            "Requirement already satisfied, skipping upgrade: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.3->numpydoc>=0.8.0->allennlp) (1.1.1)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14->OpenNMT-py) (0.2.8)\n",
            "Requirement already satisfied, skipping upgrade: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14->OpenNMT-py) (4.0)\n",
            "Requirement already satisfied, skipping upgrade: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=1.14->OpenNMT-py) (3.1.1)\n",
            "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.14->OpenNMT-py) (1.3.0)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard>=1.14->OpenNMT-py) (0.4.8)\n",
            "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=1.14->OpenNMT-py) (3.1.0)\n",
            "Building wheels for collected packages: fasttext, nltk, summa, word2number, jsonnet, parsimonious, overrides, numpydoc, ftfy, configargparse\n",
            "  Building wheel for fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext: filename=fasttext-0.9.2-cp36-cp36m-linux_x86_64.whl size=3018093 sha256=ce25e2f64738e1e6d9718e4d6bc2db8c9970279f6755b4b03f317137171f5aab\n",
            "  Stored in directory: /root/.cache/pip/wheels/98/ba/7f/b154944a1cf5a8cee91c154b75231136cc3a3321ab0e30f592\n",
            "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nltk: filename=nltk-3.5-cp36-none-any.whl size=1434676 sha256=fc67ba789968fa21a53234033a3fea2cf99d2b7073346a6adb626b6583d8b076\n",
            "  Stored in directory: /root/.cache/pip/wheels/ae/8c/3f/b1fe0ba04555b08b57ab52ab7f86023639a526d8bc8d384306\n",
            "  Building wheel for summa (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for summa: filename=summa-1.2.0-cp36-none-any.whl size=54411 sha256=c714061d35017fa5c12d91c339dd71fa9b7a02108f8cb8f6f4a16e8b83552af2\n",
            "  Stored in directory: /root/.cache/pip/wheels/6a/09/68/e2f2861c01d86407c3fa5220826ed7eed2abaa56b001be5970\n",
            "  Building wheel for word2number (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for word2number: filename=word2number-1.1-cp36-none-any.whl size=5587 sha256=64847e3ab885692b69c0056928ac1c667727f25e5b679efd88ca723baaabba84\n",
            "  Stored in directory: /root/.cache/pip/wheels/46/2f/53/5f5c1d275492f2fce1cdab9a9bb12d49286dead829a4078e0e\n",
            "  Building wheel for jsonnet (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jsonnet: filename=jsonnet-0.15.0-cp36-cp36m-linux_x86_64.whl size=3319809 sha256=7c315e9b65a5cc750faae22361d2f04474f1abe762d32382365ddffe386203ec\n",
            "  Stored in directory: /root/.cache/pip/wheels/57/63/2e/da89cfe1ba08550bd7262d5d9c027edc313980c3b85b3b0a38\n",
            "  Building wheel for parsimonious (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for parsimonious: filename=parsimonious-0.8.1-cp36-none-any.whl size=42712 sha256=fa27034539d918b10176a495bd350fbf3623eb5ca32a09706e4819aa82178edd\n",
            "  Stored in directory: /root/.cache/pip/wheels/b7/8d/e7/a0e74217da5caeb3c1c7689639b6d28ddbf9985b840bc96a9a\n",
            "  Building wheel for overrides (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for overrides: filename=overrides-2.8.0-cp36-none-any.whl size=5609 sha256=7714484e23baa21bb48bfeb1d10af4e9571a55db3b91990dce42f92a61a36f4e\n",
            "  Stored in directory: /root/.cache/pip/wheels/df/f1/ba/eaf6cd7d284d2f257dc71436ce72d25fd3be5a5813a37794ab\n",
            "  Building wheel for numpydoc (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for numpydoc: filename=numpydoc-0.9.2-cp36-none-any.whl size=31893 sha256=cfd507f59148e4ca546f2a883ae91e73983464406ac12ad59e6985e7145a3e8e\n",
            "  Stored in directory: /root/.cache/pip/wheels/96/f3/52/25c8e1f40637661d27feebc61dae16b84c7cdd93b8bc3d7486\n",
            "  Building wheel for ftfy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ftfy: filename=ftfy-5.7-cp36-none-any.whl size=44593 sha256=cb34703cce6ee7319f890cfc075d3772685529ecfd536972bf8ae3eeb2ba7f9c\n",
            "  Stored in directory: /root/.cache/pip/wheels/8e/da/59/6c8925d571aacade638a0f515960c21c0887af1bfe31908fbf\n",
            "  Building wheel for configargparse (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for configargparse: filename=ConfigArgParse-1.2.3-cp36-none-any.whl size=19328 sha256=dcdf97fac4797278c1b886f664fbd75d0478fa936077ce7fc395a4c36466e4de\n",
            "  Stored in directory: /root/.cache/pip/wheels/bd/d6/53/034032da9498bda2385cd50a51a289e88090b5da2d592b1fdf\n",
            "Successfully built fasttext nltk summa word2number jsonnet parsimonious overrides numpydoc ftfy configargparse\n",
            "\u001b[31mERROR: en-core-web-sm 2.2.5 has requirement spacy>=2.2.2, but you'll have spacy 2.1.9 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: opennmt-py 1.1.1 has requirement tqdm~=4.30.0, but you'll have tqdm 4.38.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: razdel, responses, word2number, jsonpickle, pytorch-pretrained-bert, tensorboardX, jsonnet, flask-cors, parsimonious, unidecode, overrides, numpydoc, sentencepiece, pytorch-transformers, ftfy, nltk, flaky, greenlet, gevent, preshed, blis, plac, thinc, spacy, conllu, allennlp, fasttext, torchtext, configargparse, pyonmttok, waitress, OpenNMT-py, dawg-python, pymorphy2-dicts, pymorphy2, rouge, summa\n",
            "  Found existing installation: nltk 3.2.5\n",
            "    Uninstalling nltk-3.2.5:\n",
            "      Successfully uninstalled nltk-3.2.5\n",
            "  Found existing installation: preshed 3.0.2\n",
            "    Uninstalling preshed-3.0.2:\n",
            "      Successfully uninstalled preshed-3.0.2\n",
            "  Found existing installation: blis 0.4.1\n",
            "    Uninstalling blis-0.4.1:\n",
            "      Successfully uninstalled blis-0.4.1\n",
            "  Found existing installation: plac 1.1.3\n",
            "    Uninstalling plac-1.1.3:\n",
            "      Successfully uninstalled plac-1.1.3\n",
            "  Found existing installation: thinc 7.4.0\n",
            "    Uninstalling thinc-7.4.0:\n",
            "      Successfully uninstalled thinc-7.4.0\n",
            "  Found existing installation: spacy 2.2.4\n",
            "    Uninstalling spacy-2.2.4:\n",
            "      Successfully uninstalled spacy-2.2.4\n",
            "  Found existing installation: torchtext 0.3.1\n",
            "    Uninstalling torchtext-0.3.1:\n",
            "      Successfully uninstalled torchtext-0.3.1\n",
            "Successfully installed OpenNMT-py-1.1.1 allennlp-0.9.0 blis-0.2.4 configargparse-1.2.3 conllu-1.3.1 dawg-python-0.7.2 fasttext-0.9.2 flaky-3.6.1 flask-cors-3.0.8 ftfy-5.7 gevent-20.5.0 greenlet-0.4.15 jsonnet-0.15.0 jsonpickle-1.4.1 nltk-3.5 numpydoc-0.9.2 overrides-2.8.0 parsimonious-0.8.1 plac-0.9.6 preshed-2.0.1 pymorphy2-0.8 pymorphy2-dicts-2.4.393442.3710985 pyonmttok-1.18.3 pytorch-pretrained-bert-0.6.2 pytorch-transformers-1.1.0 razdel-0.5.0 responses-0.10.14 rouge-0.3.1 sentencepiece-0.1.8 spacy-2.1.9 summa-1.2.0 tensorboardX-2.0 thinc-7.0.8 torchtext-0.4.0 unidecode-1.1.1 waitress-1.4.3 word2number-1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPkq9fXSJX3J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "liva5vCf3pVQ",
        "colab_type": "text"
      },
      "source": [
        "## EDA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eesnclfDDV3F",
        "colab_type": "text"
      },
      "source": [
        "Посмотрим на то, как устроен датасет"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mz6CZYKQhnd-",
        "colab_type": "code",
        "outputId": "eb720a43-2ba1-4c6a-a411-c2062224d7a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "source": [
        "!head -n 1 gazeta_train.txt\n",
        "!cat gazeta_train.txt | wc -l\n",
        "!cat gazeta_val.txt | wc -l\n",
        "!cat gazeta_test.txt | wc -l"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\"url\": \"https://www.gazeta.ru/financial/2011/11/30/3852658.shtml\", \"text\": \"«По итогам 2011 года чистый отток может составить примерно $80 млрд, в следующем году — около $20 млрд. При этом мы ожидаем, что со второго полугодия 2012 года начнется приток капитала», — заявил «Интерфаксу» замминистра экономического развития Андрей Клепач. Официальные прогнозы по выводу капитала из России становятся все пессимистичными: еще летом власти полагали, что из страны уйдет не более $35 млрд, в сентябре Минэкономразвития назвал цифру $50 млрд, в начале ноября Центробанк пересмотрел оценку до $70 млрд. Очередное изменение прогноза было ожидаемо: по расчетам Центробанка , за январь — октябрь чистый отток капитала достиг $64 млрд, причем в последние месяцы он ускорился: в сентябре он составил $14 млрд, в октябре — $13 млрд против среднего ежемесячного оттока в $6—8 млрд в первом полугодии. «После октябрьских данных Минэкономразвития вынуждено было изменить оценку, настаивать на $70 млрд означало ожидать серьезного замедления оттока капитала на непонятно каких причинах», — говорит главный экономист BNP Paribas Юлия Цепляева. «В последние два месяца отток капитала ускорится, на декабрь приходится значительная часть выплат по внешним долгам, что приводит к усилению оттока, особенно если они не рефинансируются новыми кредитами», — соглашается главный экономист ФК «Открытие» Владимир Тихомиров. Прогнозируемый Минэкономразвития отток капитала — один из самых высоких за последние 20 лет. Больше ушло лишь в 2008 году на фоне разрастания финансового кризиса и российско-грузинской войны — $133,7 млрд. В кризисный 2009 год из России утекло $56,1 млрд. Главный фактор ускорения оттока капитала в 2011 году — нестабильность на внешних финансовых рынках и рост опасений относительно второй волны рецессии. «Это реакция на неуверенность, которую генерирует Европа с долговыми проблемами. В случае новой волны глобальной турбулентности Россия — одна из самых уязвимых стран», — говорит Цепляева. Еще одна причина — ослабление рубля. «Привлекательность вложений снижается на фоне того, что рубль перестал укрепляться, а ставки по депозитам достаточно низкие. В результате экспортеры не полностью возвращают экспортную выручку», — говорит Тихомиров. Внутри страны эксперты не видят особых причин для бегства капитала. «Ситуация выглядит достаточно позитивно, очень хорошие макроэкономические результаты за год, особенно на фоне других стран. С политической точки зрения все достаточно понятно и предсказуемо, итог выборов очевиден», — говорит экономист ИК «Тройка Диалог» Антон Струченевский. Тем не менее политический фактор играет роль. «Бизнесу важно не только, кто будет президентом, он ждет ясности с перестановками в правительстве. В наших условиях административный ресурс важнее всего для успешности бизнеса», — говорит Цепляева, добавляя, что отток капитала продолжится до завершения президентских выборов.\", \"title\": \"Прогноз не успевает за оттоком\", \"summary\": \"В 2011 году из России уйдет $80 млрд, считают в Минэкономразвития. Менее месяца назад Центробанк давал оценку $70 млрд, повысив первоначальный прогноз вдвое. Отток капитала из страны усиливается из-за кризиса в Европе, а в декабре российским компаниям выплачивать внешние долги. На движение капитала повлияли и выборы: несмотря на их предсказуемость, бизнес хочет ясности с перестановками в правительстве.\", \"date\": \"2011-11-30 18:33:39\"}\n",
            "52400\n",
            "5265\n",
            "5770\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5pZ2UGS2DGjH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "import random\n",
        "\n",
        "def read_gazeta_records(file_name, shuffle=True, sort_by_date=False):\n",
        "    assert shuffle != sort_by_date\n",
        "    records = []\n",
        "    with open(file_name, \"r\") as r:\n",
        "        for line in r:\n",
        "            records.append(json.loads(line))\n",
        "    if sort_by_date:\n",
        "        records.sort(key=lambda x: x[\"date\"])\n",
        "    if shuffle:\n",
        "        random.shuffle\n",
        "    return records"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNDp-BunEA91",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_records = read_gazeta_records(\"gazeta_train.txt\")\n",
        "val_records = read_gazeta_records(\"gazeta_val.txt\")\n",
        "test_records = read_gazeta_records(\"gazeta_test.txt\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMNEBp7HRjE3",
        "colab_type": "code",
        "outputId": "c3ae1a66-8712-4521-e4b2-d59e633a9e94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "print(min([record[\"date\"] for record in train_records]))\n",
        "print(max([record[\"date\"] for record in train_records]))\n",
        "print(min([record[\"date\"] for record in val_records]))\n",
        "print(max([record[\"date\"] for record in val_records]))\n",
        "print(min([record[\"date\"] for record in test_records]))\n",
        "print(max([record[\"date\"] for record in test_records]))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2010-06-01 10:35:49\n",
            "2019-05-31 23:56:26\n",
            "2019-06-01 08:30:00\n",
            "2019-09-30 23:11:23\n",
            "2019-10-01 08:23:02\n",
            "2020-03-23 22:16:23\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izcJJT4dDZ_X",
        "colab_type": "text"
      },
      "source": [
        "Посчитаем статистику по словам"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5qEd6ZqENzX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import Counter, namedtuple\n",
        "import razdel\n",
        "import pymorphy2\n",
        "\n",
        "Stats = namedtuple(\"Stats\", \"vocabulary,lemma_vocabulary,words_counts,unique_words_counts\")\n",
        "\n",
        "def collect_stats(records, lower=True, text_max_words=3000, summary_max_words=100, nrows=1000):\n",
        "    morph = pymorphy2.MorphAnalyzer()\n",
        "    \n",
        "    text_stats = Stats(Counter(),  Counter(), list(), list())\n",
        "    summary_stats = Stats(Counter(),  Counter(), list(), list())\n",
        "\n",
        "    def update_record_field_stats(field, stats, max_words):\n",
        "        words = [word.text for word in razdel.tokenize(field)][:max_words]\n",
        "        lemmas = [morph.parse(word)[0].normal_form for word in words]\n",
        "        stats.vocabulary.update(words)\n",
        "        stats.lemma_vocabulary.update(lemmas)\n",
        "        stats.words_counts.append(len(words))\n",
        "        stats.unique_words_counts.append(len(set(words)))\n",
        "\n",
        "    for i, record in enumerate(records):\n",
        "        if i >= nrows:\n",
        "            break\n",
        "        text = record[\"text\"]\n",
        "        text = text if not lower else text.lower()\n",
        "        update_record_field_stats(text, text_stats, text_max_words)\n",
        "\n",
        "        summary = record[\"summary\"]\n",
        "        summary = summary if not lower else summary.lower()\n",
        "        summary_words = [word.text for word in razdel.tokenize(summary)]\n",
        "        update_record_field_stats(summary, summary_stats, summary_max_words)\n",
        "    return text_stats, summary_stats"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mtZ-lVgnImnL",
        "colab_type": "code",
        "outputId": "c87847f9-323b-46db-a82c-b4c9b1e44859",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "test_text_stats, test_summary_stats = collect_stats(test_records)\n",
        "print(\"Test texts vocabulary size: \", len(test_text_stats.vocabulary))\n",
        "print(\"Test texts lemma vocabulary size: \", len(test_text_stats.lemma_vocabulary))\n",
        "print(\"Test summaries vocabulary size: \", len(test_summary_stats.vocabulary))\n",
        "print(\"Test summaries lemma vocabulary size: \", len(test_summary_stats.lemma_vocabulary))\n",
        "print(\"Test common lemmas summary vs text: \", len(set(test_text_stats.lemma_vocabulary.keys()) & set(test_summary_stats.lemma_vocabulary.keys())))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test texts vocabulary size:  73282\n",
            "Test texts lemma vocabulary size:  32752\n",
            "Test summaries vocabulary size:  15196\n",
            "Test summaries lemma vocabulary size:  8673\n",
            "Test common lemmas summary vs text:  8408\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RnVjYhVJpHY",
        "colab_type": "code",
        "outputId": "d6429016-42ac-4472-c324-f1da59ef6083",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "test_text_stats.lemma_vocabulary.most_common(100)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(',', 54104),\n",
              " ('.', 38406),\n",
              " ('в', 28069),\n",
              " ('и', 14555),\n",
              " ('«', 12789),\n",
              " ('»', 12716),\n",
              " ('на', 11741),\n",
              " ('что', 9225),\n",
              " ('—', 8528),\n",
              " ('с', 8173),\n",
              " ('не', 7279),\n",
              " ('по', 6354),\n",
              " ('быть', 6232),\n",
              " ('он', 6206),\n",
              " ('это', 5730),\n",
              " ('год', 4998),\n",
              " ('который', 3920),\n",
              " ('о', 3888),\n",
              " ('тот', 3200),\n",
              " ('как', 2981),\n",
              " ('из', 2868),\n",
              " ('к', 2828),\n",
              " ('россия', 2713),\n",
              " ('она', 2659),\n",
              " ('они', 2632),\n",
              " ('а', 2597),\n",
              " ('свой', 2542),\n",
              " ('для', 2473),\n",
              " ('за', 2402),\n",
              " ('весь', 2327),\n",
              " ('один', 2131),\n",
              " ('также', 2105),\n",
              " ('от', 2061),\n",
              " ('этот', 1919),\n",
              " ('я', 1865),\n",
              " ('мочь', 1855),\n",
              " ('мы', 1755),\n",
              " ('у', 1725),\n",
              " ('но', 1699),\n",
              " ('страна', 1657),\n",
              " ('российский', 1589),\n",
              " ('(', 1583),\n",
              " (')', 1583),\n",
              " ('человек', 1583),\n",
              " ('президент', 1582),\n",
              " ('сша', 1578),\n",
              " ('при', 1564),\n",
              " ('до', 1523),\n",
              " ('после', 1506),\n",
              " ('время', 1500),\n",
              " ('слово', 1409),\n",
              " ('украина', 1405),\n",
              " ('заявить', 1374),\n",
              " ('стать', 1368),\n",
              " ('так', 1351),\n",
              " ('такой', 1307),\n",
              " (':', 1265),\n",
              " ('%', 1249),\n",
              " ('то', 1230),\n",
              " ('уже', 1172),\n",
              " ('однако', 1100),\n",
              " ('два', 1093),\n",
              " ('глава', 1082),\n",
              " ('же', 1034),\n",
              " ('ещё', 1032),\n",
              " ('отметить', 985),\n",
              " ('чтобы', 982),\n",
              " ('дело', 953),\n",
              " ('если', 949),\n",
              " ('другой', 919),\n",
              " ('только', 906),\n",
              " ('день', 874),\n",
              " ('должный', 869),\n",
              " ('американский', 854),\n",
              " ('тем', 840),\n",
              " ('более', 827),\n",
              " ('говорить', 798),\n",
              " ('большой', 797),\n",
              " ('компания', 792),\n",
              " ('сторона', 782),\n",
              " ('или', 778),\n",
              " ('тысяча', 773),\n",
              " ('украинский', 766),\n",
              " ('сообщить', 764),\n",
              " ('сказать', 757),\n",
              " ('самый', 755),\n",
              " ('новый', 755),\n",
              " ('москва', 747),\n",
              " ('ранее', 746),\n",
              " ('–', 745),\n",
              " ('вопрос', 744),\n",
              " ('ребёнок', 741),\n",
              " ('военный', 728),\n",
              " ('когда', 706),\n",
              " ('отношение', 705),\n",
              " ('трамп', 700),\n",
              " ('себя', 681),\n",
              " ('дать', 677),\n",
              " ('власть', 666),\n",
              " ('представитель', 658)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6BohYCZJH7H",
        "colab_type": "code",
        "outputId": "1e2abee1-4f4b-46e2-d2d6-681bddfdc651",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.hist(test_text_stats.words_counts, 20)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([  8.,  15.,  38.,  94., 236., 224., 138.,  65.,  25.,  26.,  25.,\n",
              "         21.,  14.,  14.,  14.,   6.,  12.,   8.,   6.,  11.]),\n",
              " array([ 408. ,  462.5,  517. ,  571.5,  626. ,  680.5,  735. ,  789.5,\n",
              "         844. ,  898.5,  953. , 1007.5, 1062. , 1116.5, 1171. , 1225.5,\n",
              "        1280. , 1334.5, 1389. , 1443.5, 1498. ]),\n",
              " <a list of 20 Patch objects>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LvE1j1P8NSvx",
        "colab_type": "code",
        "outputId": "4e07ecfb-5786-4b3b-8521-cc39e7bedb83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.hist(test_text_stats.unique_words_counts, 20)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([  6.,   8.,  34., 103., 291., 233., 121.,  49.,  30.,  33.,  17.,\n",
              "         14.,  23.,  10.,   8.,   9.,   6.,   2.,   2.,   1.]),\n",
              " array([229. , 260.7, 292.4, 324.1, 355.8, 387.5, 419.2, 450.9, 482.6,\n",
              "        514.3, 546. , 577.7, 609.4, 641.1, 672.8, 704.5, 736.2, 767.9,\n",
              "        799.6, 831.3, 863. ]),\n",
              " <a list of 20 Patch objects>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYKvqKwfSCaC",
        "colab_type": "code",
        "outputId": "4d756288-99ae-4b16-bade-63a143a0cffd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.hist(test_summary_stats.words_counts, 20)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([  3.,   5.,  20.,  23.,  32.,  53.,  64.,  82., 126.,  91.,  79.,\n",
              "         89.,  91.,  64.,  63.,  38.,  38.,  15.,  15.,   9.]),\n",
              " array([20.  , 23.25, 26.5 , 29.75, 33.  , 36.25, 39.5 , 42.75, 46.  ,\n",
              "        49.25, 52.5 , 55.75, 59.  , 62.25, 65.5 , 68.75, 72.  , 75.25,\n",
              "        78.5 , 81.75, 85.  ]),\n",
              " <a list of 20 Patch objects>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHNXD0xBNcY0",
        "colab_type": "code",
        "outputId": "c5bef710-eda7-48ef-a532-281e963ccc68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "train_text_stats, train_summary_stats = collect_stats(train_records)\n",
        "print(\"Train texts vocabulary size: \", len(train_text_stats.vocabulary))\n",
        "print(\"Train texts lemma vocabulary size: \", len(train_text_stats.lemma_vocabulary))\n",
        "print(\"Train summaries vocabulary size: \", len(train_summary_stats.vocabulary))\n",
        "print(\"Train summaries lemma vocabulary size: \", len(train_summary_stats.lemma_vocabulary))\n",
        "print(\"Train common lemmas summary vs text: \", len(set(train_text_stats.lemma_vocabulary.keys()) & set(train_summary_stats.lemma_vocabulary.keys())))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train texts vocabulary size:  82978\n",
            "Train texts lemma vocabulary size:  38089\n",
            "Train summaries vocabulary size:  15441\n",
            "Train summaries lemma vocabulary size:  9087\n",
            "Train common lemmas summary vs text:  8703\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zvj9vPaQNtz6",
        "colab_type": "code",
        "outputId": "85774e2e-3ed0-4fca-a42e-44d71a13d76d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(\"Text common lemmas train vs test: \", len(set(train_text_stats.lemma_vocabulary.keys()) & set(test_text_stats.lemma_vocabulary.keys())))\n",
        "print(\"Summary common lemmas train vs test: \", len(set(train_summary_stats.lemma_vocabulary.keys()) & set(test_summary_stats.lemma_vocabulary.keys())))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Text common lemmas train vs test:  18875\n",
            "Summary common lemmas train vs test:  4508\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CJCd1qZOl6P",
        "colab_type": "code",
        "outputId": "059faf66-9bec-4234-8087-529b313657b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.hist(train_text_stats.words_counts, 20)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([  1.,   1.,   2.,  17.,  59.,  76., 112., 179., 144., 108.,  82.,\n",
              "         53.,  43.,  34.,  31.,  24.,  14.,   6.,   5.,   9.]),\n",
              " array([ 167.  ,  233.25,  299.5 ,  365.75,  432.  ,  498.25,  564.5 ,\n",
              "         630.75,  697.  ,  763.25,  829.5 ,  895.75,  962.  , 1028.25,\n",
              "        1094.5 , 1160.75, 1227.  , 1293.25, 1359.5 , 1425.75, 1492.  ]),\n",
              " <a list of 20 Patch objects>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1sl7s2qB-N_",
        "colab_type": "text"
      },
      "source": [
        "## Lead-3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gBNeldXoDevM",
        "colab_type": "text"
      },
      "source": [
        "Первый baseline - первые 3 предложения текста в качестве summary.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-gEkSkQDk0P",
        "colab_type": "text"
      },
      "source": [
        "В качестве метрик здесь и далее используем BLEU и ROUGE."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fVfdfCyCALH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "from rouge import Rouge\n",
        "\n",
        "def calc_scores(references, predictions, metric=\"all\"):\n",
        "    print(\"Count:\", len(predictions))\n",
        "    print(\"Ref:\", references[-1])\n",
        "    print(\"Hyp:\", predictions[-1])\n",
        "\n",
        "    if metric in (\"bleu\", \"all\"):\n",
        "        print(\"BLEU: \", corpus_bleu([[r] for r in references], predictions))\n",
        "    if metric in (\"rouge\", \"all\"):\n",
        "        rouge = Rouge()\n",
        "        scores = rouge.get_scores(predictions, references, avg=True)\n",
        "        print(\"ROUGE: \", scores)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAo9zv_rPtb6",
        "colab_type": "code",
        "outputId": "ed7d7ff4-ecb5-4803-d9f6-0b33ab2bada6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "import razdel\n",
        "\n",
        "def calc_lead_n_score(records, n=3, lower=True, nrows=1000):\n",
        "    references = []\n",
        "    predictions = []\n",
        "\n",
        "    for i, record in enumerate(records):\n",
        "        if i >= nrows:\n",
        "            break\n",
        "\n",
        "        summary = record[\"summary\"]\n",
        "        summary = summary if not lower else summary.lower()\n",
        "        references.append(summary)\n",
        "\n",
        "        text = record[\"text\"]\n",
        "        text = text if not lower else text.lower()\n",
        "        sentences = [sentence.text for sentence in razdel.sentenize(text)]\n",
        "        prediction = \" \".join(sentences[:n])\n",
        "        predictions.append(prediction)\n",
        "\n",
        "    calc_scores(references, predictions)\n",
        "\n",
        "calc_lead_n_score(test_records, n=1)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Count: 1000\n",
            "Ref: телеканал «спас» запускает реалити-шоу «остров», участникам которого предстоит месяц жить и работать в нило-столобенской пустыни на озере селигер. организаторы отметили, что это беспрецедентный подобный проект на телевидении. участникам шоу будет, где поработать — в монастыре работают свечной, молочный и столярный цеха, есть коровник, конюшня, пасека.\n",
            "Hyp: православный телеканал «спас», учредителем которого является московская патриархия, запускает реалити-шоу «остров», участникам которого предстоит месяц жить и работать в нило-столобенской пустыни на озере селигер в тверской области.\n",
            "BLEU:  0.19177311186434495\n",
            "ROUGE:  {'rouge-1': {'f': 0.23804097238957525, 'p': 0.22208274285774904, 'r': 0.37762764047433917}, 'rouge-2': {'f': 0.10027796832321115, 'p': 0.09647636782929753, 'r': 0.15833772153385062}, 'rouge-l': {'f': 0.1835646488408507, 'p': 0.2022959168891477, 'r': 0.34937017731940756}}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QsAcVSli3r3S",
        "colab_type": "text"
      },
      "source": [
        "##TextRank"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7jAQp-_Ds98",
        "colab_type": "text"
      },
      "source": [
        "TextRank - unsupervised метод для составления кратких выжимок из текста. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bOatiZ-hFJT-",
        "colab_type": "text"
      },
      "source": [
        "### Самописный TextRank"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2GwyRrMPAzS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from itertools import combinations\n",
        "import networkx as nx\n",
        "import pymorphy2\n",
        "import numpy as np\n",
        "\n",
        "def unique_words_similarity(words1, words2):\n",
        "    '''\n",
        "    Функция подсчёта близости предложений на основе пересечения слов\n",
        "    ''' \n",
        "    words1 = set(words1)\n",
        "    words2 = set(words2)\n",
        "    if not len(words1) or not len(words2):\n",
        "        return 0.0\n",
        "    return len(words1.intersection(words2))/(np.log10(len(words1)) + np.log10(len(words2)))\n",
        "\n",
        "def gen_text_rank_summary(text, calc_similarity=unique_words_similarity, summary_part=0.1, lower=True, morph=None):\n",
        "    '''\n",
        "    Составление summary с помощью TextRank\n",
        "    '''\n",
        "    # Разбиваем текст на предложения\n",
        "    sentences = [sentence.text for sentence in razdel.sentenize(text)]\n",
        "    n_sentences = len(sentences)\n",
        "\n",
        "    # Токенизируем предложения\n",
        "    sentences_words = [[token.text.lower() if lower else token.text for token in razdel.tokenize(sentence)] for sentence in sentences]\n",
        "\n",
        "    # При необходимости лемматизируем слова\n",
        "    if morph is not None:\n",
        "        sentences_words = [[morph.parse(word)[0].normal_form for word in words] for words in sentences_words]\n",
        "\n",
        "    # Для каждой пары предложений считаем близость\n",
        "    pairs = combinations(range(n_sentences), 2)\n",
        "    scores = [(i, j, calc_similarity(sentences_words[i], sentences_words[j])) for i, j in pairs]\n",
        "\n",
        "    # Строим граф с рёбрами, равными близости между предложениями\n",
        "    g = nx.Graph()\n",
        "    g.add_weighted_edges_from(scores)\n",
        "\n",
        "    # Считаем PageRank\n",
        "    pr = nx.pagerank(g)\n",
        "    result = [(i, pr[i], s) for i, s in enumerate(sentences) if i in pr]\n",
        "    result.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    # Выбираем топ предложений\n",
        "    n_summary_sentences = max(int(n_sentences * summary_part), 1)\n",
        "    result = result[:n_summary_sentences]\n",
        "\n",
        "    # Восстанавливаем оригинальный их порядок\n",
        "    result.sort(key=lambda x: x[0])\n",
        "\n",
        "    # Восстанавливаем текст выжимки\n",
        "    predicted_summary = \" \".join([sentence for i, proba, sentence in result])\n",
        "    predicted_summary = predicted_summary.lower() if lower else predicted_summary\n",
        "    return predicted_summary\n",
        "\n",
        "def calc_text_rank_score(records, calc_similarity=unique_words_similarity, summary_part=0.1, lower=True, nrows=1000, morph=None):\n",
        "    references = []\n",
        "    predictions = []\n",
        "\n",
        "    for i, record in enumerate(records):\n",
        "        if i >= nrows:\n",
        "            break\n",
        "\n",
        "        summary = record[\"summary\"]\n",
        "        summary = summary if not lower else summary.lower()\n",
        "        references.append(summary)\n",
        "\n",
        "        text = record[\"text\"]\n",
        "        predicted_summary = gen_text_rank_summary(text, calc_similarity, summary_part, lower, morph=morph)\n",
        "        text = text if not lower else text.lower()\n",
        "        predictions.append(predicted_summary)\n",
        "\n",
        "    calc_scores(references, predictions)\n",
        "\n",
        "morph = pymorphy2.MorphAnalyzer()\n",
        "# calc_text_rank_score(test_records)\n",
        "# calc_text_rank_score(test_records, morph=morph)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ac8UYVqJOLg6",
        "colab_type": "text"
      },
      "source": [
        "### **Задание 1**\n",
        "\n",
        "Сделайте TextRank с другой мерой близости предложений: по FastText, ELMo или BERT эмбеддингам"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92Xl74Cr5ydn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from gensim.models import FastText\n",
        "from scipy.linalg import norm\n",
        "\n",
        "fasttext_model = FastText.load_fasttext_format(\"cc.ru.300.bin\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXfTN2q79RX6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1d326d1b-298b-456e-ed62-263588f12070"
      },
      "source": [
        "'огп' in fasttext_model.wv"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bHwXcGGnz5R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "6a1c2802-d8b2-4324-f896-472266ccb219"
      },
      "source": [
        "def fasttext_similarity(words1, words2):\n",
        "    def get_seq_vector(words):\n",
        "        vectors = []\n",
        "        for word in words:\n",
        "            if word in fasttext_model.wv:\n",
        "                vectors.append(fasttext_model.wv[word])\n",
        "        return np.mean(vectors, axis=0)\n",
        "\n",
        "    u = get_seq_vector(words1)\n",
        "    v = get_seq_vector(words2)\n",
        "\n",
        "    return np.dot(u, v) / (norm(u) * norm(v))\n",
        "\n",
        "calc_text_rank_score(test_records, calc_similarity=fasttext_similarity, morph=morph)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Count: 1000\n",
            "Ref: телеканал «спас» запускает реалити-шоу «остров», участникам которого предстоит месяц жить и работать в нило-столобенской пустыни на озере селигер. организаторы отметили, что это беспрецедентный подобный проект на телевидении. участникам шоу будет, где поработать — в монастыре работают свечной, молочный и столярный цеха, есть коровник, конюшня, пасека.\n",
            "Hyp: проживи месяц в ниловой пустыни, выполняя послушания, и найди ответы на вопросы, которые давно беспокоят», — так анонсирует телеканал свой проект. церковь призывает молиться об усопших, а не делать хайп на их смерти», — указал он. «если человеку невоцерковленному, далекому от церкви, в двух словах сказать, для чего нужна церковь — церковь… нужна для того, чтобы был силен дух нашего народа», — говорил предстоятель. по его словам, такая зависимость сродни алкогольной или наркотической — электронные устройства лишают человека свободы и приводят к «дегуманизации» личности, уводя в виртуальную реальность.\n",
            "BLEU:  0.26830747428140844\n",
            "ROUGE:  {'rouge-1': {'f': 0.1422555258089773, 'p': 0.11759097683699035, 'r': 0.19456167167330016}, 'rouge-2': {'f': 0.0271265622541159, 'p': 0.022094167679619497, 'r': 0.0384047583679983}, 'rouge-l': {'f': 0.11247505452645916, 'p': 0.10443321940607327, 'r': 0.17312843628180227}}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zcvpfvCVvfP0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "config = {\n",
        "  \"chainer\": {\n",
        "    \"in\": [\"texts\"],\n",
        "    \"pipe\": [\n",
        "      {\n",
        "        \"class_name\": \"transformers_bert_preprocessor\",\n",
        "        \"vocab_file\": \"{BERT_PATH}/vocab.txt\",\n",
        "        \"do_lower_case\": false,\n",
        "        \"max_seq_length\": 512,\n",
        "        \"in\": [\"texts\"],\n",
        "        \"out\": [\"tokens\", \"subword_tokens\", \"subword_tok_ids\", \"startofword_markers\", \"attention_mask\"]\n",
        "      },\n",
        "      {\n",
        "        \"class_name\": \"transformers_bert_embedder\",\n",
        "        \"bert_config_path\": \"{BERT_PATH}/bert_config.json\",\n",
        "        \"load_path\": \"{BERT_PATH}\",\n",
        "        \"truncate\": true,\n",
        "        \"in\": [\"subword_tok_ids\", \"startofword_markers\", \"attention_mask\"],\n",
        "        \"out\": [\"word_emb\", \"subword_emb\", \"max_emb\", \"mean_emb\", \"pooler_output\"]\n",
        "      }\n",
        "    ],\n",
        "    \"out\": [\"tokens\", \"word_emb\", \"subword_tokens\", \"subword_emb\", \"max_emb\", \"mean_emb\", \"pooler_output\"]\n",
        "  },\n",
        "  \"train\": {},\n",
        "  \"metadata\": {\n",
        "    \"variables\": {\n",
        "      \"ROOT_PATH\": \"~/.deeppavlov\",\n",
        "      \"DOWNLOADS_PATH\": \"{ROOT_PATH}/downloads\",\n",
        "      \"BERT_PATH\": \"{DOWNLOADS_PATH}/bert_models/multi_cased_L-12_H-768_A-12_pt\"\n",
        "    },\n",
        "    \"requirements\": [\n",
        "      \"{DEEPPAVLOV_PATH}/requirements/transformers.txt\",\n",
        "      \"{DEEPPAVLOV_PATH}/requirements/pytorch.txt\"\n",
        "    ],\n",
        "    \"labels\": {},\n",
        "    \"download\": [\n",
        "      {\n",
        "        \"url\": \"http://files.deeppavlov.ai/deeppavlov_data/bert/multi_cased_L-12_H-768_A-12_pt.tar.gz\",\n",
        "        \"subdir\": \"{DOWNLOADS_PATH}/bert_models\"\n",
        "      }\n",
        "    ]\n",
        "  }\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGFTmGLLFOGw",
        "colab_type": "text"
      },
      "source": [
        "### Summa"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQiUDH8fVN3h",
        "colab_type": "code",
        "outputId": "3c41e0df-f672-47dc-ae96-972908ebf70f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from summa.summarizer import summarize\n",
        "\n",
        "def calc_summa_score(records, summary_part=0.1, lower=True, nrows=1000):\n",
        "    references = []\n",
        "    predictions = []\n",
        "\n",
        "    for i, record in enumerate(records):\n",
        "        if i >= nrows:\n",
        "            break\n",
        "\n",
        "        summary = record[\"summary\"]\n",
        "        summary = summary if not lower else summary.lower()\n",
        "        references.append(summary)\n",
        "\n",
        "        text = record[\"text\"]\n",
        "        text = text if not lower else text.lower()\n",
        "        predicted_summary = summarize(text, ratio=summary_part, language='russian').replace(\"\\n\", \" \")\n",
        "        predictions.append(predicted_summary)\n",
        "\n",
        "    calc_scores(references, predictions)\n",
        "\n",
        "calc_summa_score(test_records)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Count: 1000\n",
            "Ref: телеканал «спас» запускает реалити-шоу «остров», участникам которого предстоит месяц жить и работать в нило-столобенской пустыни на озере селигер. организаторы отметили, что это беспрецедентный подобный проект на телевидении. участникам шоу будет, где поработать — в монастыре работают свечной, молочный и столярный цеха, есть коровник, конюшня, пасека.\n",
            "Hyp: проживи месяц в ниловой пустыни, выполняя послушания, и найди ответы на вопросы, которые давно беспокоят», — так анонсирует телеканал свой проект. «у нас же даже многие журналисты не знают и не понимают многого, связанного с религиозными ценностями, а здесь — попытка обратить их внимание на это, может быть, им будет интересно. стоит отметить, что участникам шоу будет, где поработать — в монастыре работают свечной, молочный и столярный цеха, есть коровник, конюшня, пасека. и это что — жизнь, что ли?\n",
            "BLEU:  0.2762958192799957\n",
            "ROUGE:  {'rouge-1': {'f': 0.1770425497877709, 'p': 0.14391909693539454, 'r': 0.24737876331285494}, 'rouge-2': {'f': 0.047316399226292105, 'p': 0.03775600414501152, 'r': 0.06889084948510987}, 'rouge-l': {'f': 0.13869575224542852, 'p': 0.12795603134013936, 'r': 0.2198206686289155}}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xdTrfxycB7cd",
        "colab_type": "text"
      },
      "source": [
        "## Oracle summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Q7DeHDYFSjX",
        "colab_type": "text"
      },
      "source": [
        "Для сведения задачи к extractive summarization мы должны выбрать те предложения из оригинального текста, которые наиболее похожи на наше целевое summary по нашим метрикам."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sxsc0Orf8hGq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import copy\n",
        "\n",
        "def build_oracle_summary_greedy(text, gold_summary, calc_score, lower=True, max_sentences=30):\n",
        "    '''\n",
        "    Жадное построение oracle summary\n",
        "    '''\n",
        "    gold_summary = gold_summary.lower() if lower else gold_summary\n",
        "    # Делим текст на предложения\n",
        "    sentences = [sentence.text.lower() if lower else sentence.text for sentence in razdel.sentenize(text)][:max_sentences]\n",
        "    n_sentences = len(sentences)\n",
        "    oracle_summary_sentences = set()\n",
        "    score = -1.0\n",
        "    summaries = []\n",
        "    for _ in range(n_sentences):\n",
        "        for i in range(n_sentences):\n",
        "            if i in oracle_summary_sentences:\n",
        "                continue\n",
        "            current_summary_sentences = copy.copy(oracle_summary_sentences)\n",
        "            # Добавляем какое-то предложения к уже существующему summary\n",
        "            current_summary_sentences.add(i)\n",
        "            current_summary = \" \".join([sentences[index] for index in sorted(list(current_summary_sentences))])\n",
        "            # Считаем метрики\n",
        "            current_score = calc_score(current_summary, gold_summary)\n",
        "            summaries.append((current_score, current_summary_sentences))\n",
        "        # Если получилось улучшить метрики с добавлением какого-либо предложения, то пробуем добавить ещё\n",
        "        # Иначе на этом заканчиваем\n",
        "        best_summary_score, best_summary_sentences = max(summaries)\n",
        "        if best_summary_score <= score:\n",
        "            break\n",
        "        oracle_summary_sentences = best_summary_sentences\n",
        "        score = best_summary_score\n",
        "    oracle_summary = \" \".join([sentences[index] for index in sorted(list(oracle_summary_sentences))])\n",
        "    return oracle_summary, oracle_summary_sentences\n",
        "\n",
        "def calc_single_score(pred_summary, gold_summary, rouge):\n",
        "    return rouge.get_scores([pred_summary], [gold_summary], avg=True)['rouge-2']['f']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7T_ak-KDB8rp",
        "colab_type": "code",
        "outputId": "8fd999a7-cb69-4c67-95e6-2b49eb9f4444",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "def calc_oracle_score(records, nrows=1000, lower=True):\n",
        "    references = []\n",
        "    predictions = []\n",
        "    rouge = Rouge()\n",
        "  \n",
        "    for i, record in enumerate(records):\n",
        "        if i >= nrows:\n",
        "            break\n",
        "\n",
        "        summary = record[\"summary\"]\n",
        "        summary = summary if not lower else summary.lower()\n",
        "        references.append(summary)\n",
        "\n",
        "        text = record[\"text\"]\n",
        "        predicted_summary, _ = build_oracle_summary_greedy(text, summary, calc_score=lambda x, y: calc_single_score(x, y, rouge))\n",
        "        predictions.append(predicted_summary)\n",
        "\n",
        "    calc_scores(references, predictions)\n",
        "\n",
        "\n",
        "calc_oracle_score(test_records)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Count: 1000\n",
            "Ref: телеканал «спас» запускает реалити-шоу «остров», участникам которого предстоит месяц жить и работать в нило-столобенской пустыни на озере селигер. организаторы отметили, что это беспрецедентный подобный проект на телевидении. участникам шоу будет, где поработать — в монастыре работают свечной, молочный и столярный цеха, есть коровник, конюшня, пасека.\n",
            "Hyp: православный телеканал «спас», учредителем которого является московская патриархия, запускает реалити-шоу «остров», участникам которого предстоит месяц жить и работать в нило-столобенской пустыни на озере селигер в тверской области. в комментарии также отмечается, что это беспрецедентный подобный проект на телевидении. стоит отметить, что участникам шоу будет, где поработать — в монастыре работают свечной, молочный и столярный цеха, есть коровник, конюшня, пасека.\n",
            "BLEU:  0.531336150784986\n",
            "ROUGE:  {'rouge-1': {'f': 0.36951810858804146, 'p': 0.4053281117404892, 'r': 0.3661389123393327}, 'rouge-2': {'f': 0.2087846693590912, 'p': 0.23400300931194973, 'r': 0.20594499639015063}, 'rouge-l': {'f': 0.32342889691715343, 'p': 0.3777106006444112, 'r': 0.33982247044123787}}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "foLYftYTCAkS",
        "colab_type": "text"
      },
      "source": [
        "## Extractive RNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PYrjp9FtGdST",
        "colab_type": "text"
      },
      "source": [
        "Теперь пробуем предсказать oracle summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Sfauc4VGgyw",
        "colab_type": "text"
      },
      "source": [
        "### BPE\n",
        "Для начала сделаем BPE токенизацию"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFx_UMNTXJGX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qIRKm4TCHzN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "from sentencepiece import SentencePieceTrainer\n",
        "\n",
        "def train_bpe(records, model_path, model_type=\"bpe\", vocab_size=15000, lower=True):\n",
        "    temp_file_name = \"temp.txt\"\n",
        "    with open(temp_file_name, \"w\") as temp:\n",
        "        for record in train_records:\n",
        "            summary = record[\"summary\"].strip()\n",
        "            text = record[\"text\"].strip()\n",
        "            if lower:\n",
        "                summary = summary.lower()\n",
        "                text = text.lower()\n",
        "            if not text or not summary:\n",
        "                continue\n",
        "            temp.write(text + \"\\n\")\n",
        "            temp.write(summary + \"\\n\")\n",
        "    if not os.path.exists(model_path):\n",
        "        os.makedirs(model_path)\n",
        "    cmd = \"--input={} --model_prefix={} --vocab_size={} --model_type={}\".format(\n",
        "        temp_file_name,\n",
        "        os.path.join(model_path, model_type),\n",
        "        vocab_size,\n",
        "        model_type)\n",
        "    SentencePieceTrainer.Train(cmd)\n",
        "\n",
        "!rm -f bpe.model\n",
        "!rm -f bpe.vocab\n",
        "train_bpe(train_records, \"./\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rSMC-8J3g9MR",
        "colab_type": "code",
        "outputId": "0a56cde0-790f-4716-d05b-9764d479762e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "!head bpe.vocab\n",
        "!cat bpe.vocab | wc -l"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<unk>\t0\n",
            "<s>\t0\n",
            "</s>\t0\n",
            "▁п\t-0\n",
            "▁с\t-1\n",
            "▁в\t-2\n",
            "ро\t-3\n",
            "ст\t-4\n",
            "ра\t-5\n",
            "на\t-6\n",
            "15000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xAkZ2f5LhWwE",
        "colab_type": "code",
        "outputId": "0c4023e0-9811-4de8-8562-62ecbf78003c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sentencepiece import SentencePieceProcessor\n",
        "\n",
        "bpe_processor = SentencePieceProcessor()\n",
        "bpe_processor.Load(\"bpe.model\")\n",
        "\n",
        "def bpe_tokenize(text, bpe_processor):\n",
        "    return bpe_processor.EncodeAsPieces(text)\n",
        "\n",
        "bpe_tokenize(\"октябрь богат на изменения\", bpe_processor)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['▁октябрь', '▁бога', 'т', '▁на', '▁изменения']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AOkUL_YIGp-S",
        "colab_type": "text"
      },
      "source": [
        "### Словарь\n",
        "Составим словарь для индексации токенов"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GhQYN1beiVEC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import Counter\n",
        "from typing import List, Tuple\n",
        "import os\n",
        "\n",
        "class Vocabulary:\n",
        "    def __init__(self):\n",
        "        self.index2word = list()\n",
        "        self.word2index = dict()\n",
        "        self.word2count = Counter()\n",
        "        self.reset()\n",
        "\n",
        "    def get_pad(self):\n",
        "        return self.word2index[\"<pad>\"]\n",
        "\n",
        "    def get_sos(self):\n",
        "        return self.word2index[\"<sos>\"]\n",
        "\n",
        "    def get_eos(self):\n",
        "        return self.word2index[\"<eos>\"]\n",
        "\n",
        "    def get_unk(self):\n",
        "        return self.word2index[\"<unk>\"]\n",
        "\n",
        "    def add_word(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = len(self.index2word)\n",
        "            self.word2count[word] += 1\n",
        "            self.index2word.append(word)\n",
        "        else:\n",
        "            self.word2count[word] += 1\n",
        "    \n",
        "    def has_word(self, word) -> bool:\n",
        "        return word in self.word2index\n",
        "\n",
        "    def get_index(self, word):\n",
        "        if word in self.word2index:\n",
        "            return self.word2index[word]\n",
        "        return self.get_unk()\n",
        "\n",
        "    def get_word(self, index):\n",
        "        return self.index2word[index]\n",
        "\n",
        "    def size(self):\n",
        "        return len(self.index2word)\n",
        "\n",
        "    def is_empty(self):\n",
        "        empty_size = 4\n",
        "        return self.size() <= empty_size\n",
        "\n",
        "    def shrink(self, n):\n",
        "        best_words = self.word2count.most_common(n)\n",
        "        self.reset()\n",
        "        for word, count in best_words:\n",
        "            self.add_word(word)\n",
        "            self.word2count[word] = count\n",
        "\n",
        "    def reset(self):\n",
        "        self.word2count = Counter()\n",
        "        self.index2word = [\"<pad>\", \"<sos>\", \"<eos>\", \"<unk>\"]\n",
        "        self.word2index = {word: index for index, word in enumerate(self.index2word)}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qvZtNcOifAn",
        "colab_type": "code",
        "outputId": "d79b4c7b-1a8c-4118-eb6a-2b070392cef2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "def build_vocabulary(records, bpe_processor, lower=True): \n",
        "    vocabulary = Vocabulary()\n",
        "    for record in records:\n",
        "        text = record[\"text\"]\n",
        "        text = text.lower() if lower else text\n",
        "        tokens = bpe_tokenize(text, bpe_processor)\n",
        "        for token in tokens:\n",
        "            vocabulary.add_word(token)\n",
        "    return vocabulary\n",
        "\n",
        "vocabulary = build_vocabulary(train_records, bpe_processor)\n",
        "print(vocabulary.word2count.most_common(100)) "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(',', 2467870), ('.', 1770601), ('▁в', 1432966), ('▁и', 856627), ('▁«', 769136), ('▁на', 667157), ('▁не', 458901), ('▁—', 423218), ('▁с', 407759), ('▁что', 399348), ('▁по', 355321), ('»', 349402), ('-', 299470), ('»,', 239006), ('▁за', 198471), ('▁а', 198254), ('▁из', 182499), ('».', 172453), ('▁о', 164747), ('▁к', 163134), ('▁у', 146741), ('▁от', 143396), ('▁но', 141837), ('▁как', 135981), ('ли', 128134), ('л', 124445), ('▁он', 124281), ('▁до', 124190), ('▁это', 116988), ('▁для', 116766), ('▁(', 116117), ('▁его', 110776), ('ла', 108900), ('но', 106047), ('м', 105072), ('▁при', 103694), ('на', 100694), ('ка', 94019), ('▁года', 92684), ('т', 92201), (':', 92057), ('в', 90927), ('с', 90879), ('ной', 87275), ('▁,', 86516), ('▁также', 83781), ('▁все', 82822), ('▁после', 79961), ('▁россии', 79895), ('ми', 79323), ('▁–', 79219), ('та', 77078), ('▁то', 76579), ('ть', 75498), ('▁', 75010), ('ных', 74458), ('▁со', 74384), ('х', 74290), ('к', 73601), ('я', 72829), ('е', 71302), ('ло', 70528), ('▁будет', 70034), ('▁во', 69673), ('то', 69624), ('ного', 68330), ('▁уже', 68024), ('▁же', 67692), ('ный', 67687), ('ки', 67213), ('не', 65982), ('ные', 65470), ('▁так', 63462), ('▁был', 63262), ('н', 63128), ('▁я', 63106), ('за', 62000), ('▁было', 61160), ('▁этом', 60674), ('▁году', 60119), ('▁под', 60044), ('ны', 59861), ('ным', 59645), (')', 59491), ('▁еще', 59108), ('да', 58391), ('▁вы', 58118), ('у', 55815), ('ю', 54977), ('▁про', 54942), ('▁мы', 54801), ('▁раз', 53906), ('р', 52947), ('▁только', 52138), ('са', 52119), ('ра', 52076), ('▁время', 52006), ('ку', 51403), ('д', 51262), ('й', 50839)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "seH13yXuGt03",
        "colab_type": "text"
      },
      "source": [
        "### Кэш oracle summary\n",
        "Закэшируем oracle summary, чтобы не пересчитывать их каждый раз"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jdb-39jO-72q",
        "colab_type": "code",
        "outputId": "da8d1872-2aa9-4ad5-a93a-a343ccd94aef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from rouge import Rouge\n",
        "import razdel\n",
        "\n",
        "def add_oracle_summary_to_records(records, max_sentences=30, lower=True, nrows=1000):\n",
        "    rouge = Rouge()\n",
        "    for i, record in enumerate(records):\n",
        "        if i >= nrows:\n",
        "            break\n",
        "        if i % 128 == 0:\n",
        "            print(i)\n",
        "        text = record[\"text\"]\n",
        "        summary = record[\"summary\"]\n",
        "        summary = summary.lower() if lower else summary\n",
        "        sentences = [sentence.text.lower() if lower else sentence.text for sentence in razdel.sentenize(text)][:max_sentences]\n",
        "        oracle_summary, sentences_indicies = build_oracle_summary_greedy(text, summary, calc_score=lambda x, y: calc_single_score(x, y, rouge),\n",
        "                                                                         lower=lower, max_sentences=max_sentences)\n",
        "        record[\"sentences\"] = sentences\n",
        "        record[\"oracle_sentences\"] = list(sentences_indicies)\n",
        "        record[\"oracle_summary\"] = oracle_summary\n",
        "    return records[:nrows]\n",
        "\n",
        "ext_train_records = add_oracle_summary_to_records(train_records, nrows=16384)\n",
        "ext_val_records = add_oracle_summary_to_records(val_records, nrows=1024)\n",
        "ext_test_records = add_oracle_summary_to_records(test_records, nrows=1024)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "128\n",
            "256\n",
            "384\n",
            "512\n",
            "640\n",
            "768\n",
            "896\n",
            "1024\n",
            "1152\n",
            "1280\n",
            "1408\n",
            "1536\n",
            "1664\n",
            "1792\n",
            "1920\n",
            "2048\n",
            "2176\n",
            "2304\n",
            "2432\n",
            "2560\n",
            "2688\n",
            "2816\n",
            "2944\n",
            "3072\n",
            "3200\n",
            "3328\n",
            "3456\n",
            "3584\n",
            "3712\n",
            "3840\n",
            "3968\n",
            "4096\n",
            "4224\n",
            "4352\n",
            "4480\n",
            "4608\n",
            "4736\n",
            "4864\n",
            "4992\n",
            "5120\n",
            "5248\n",
            "5376\n",
            "5504\n",
            "5632\n",
            "5760\n",
            "5888\n",
            "6016\n",
            "6144\n",
            "6272\n",
            "6400\n",
            "6528\n",
            "6656\n",
            "6784\n",
            "6912\n",
            "7040\n",
            "7168\n",
            "7296\n",
            "7424\n",
            "7552\n",
            "7680\n",
            "7808\n",
            "7936\n",
            "8064\n",
            "8192\n",
            "8320\n",
            "8448\n",
            "8576\n",
            "8704\n",
            "8832\n",
            "8960\n",
            "9088\n",
            "9216\n",
            "9344\n",
            "9472\n",
            "9600\n",
            "9728\n",
            "9856\n",
            "9984\n",
            "10112\n",
            "10240\n",
            "10368\n",
            "10496\n",
            "10624\n",
            "10752\n",
            "10880\n",
            "11008\n",
            "11136\n",
            "11264\n",
            "11392\n",
            "11520\n",
            "11648\n",
            "11776\n",
            "11904\n",
            "12032\n",
            "12160\n",
            "12288\n",
            "12416\n",
            "12544\n",
            "12672\n",
            "12800\n",
            "12928\n",
            "13056\n",
            "13184\n",
            "13312\n",
            "13440\n",
            "13568\n",
            "13696\n",
            "13824\n",
            "13952\n",
            "14080\n",
            "14208\n",
            "14336\n",
            "14464\n",
            "14592\n",
            "14720\n",
            "14848\n",
            "14976\n",
            "15104\n",
            "15232\n",
            "15360\n",
            "15488\n",
            "15616\n",
            "15744\n",
            "15872\n",
            "16000\n",
            "16128\n",
            "16256\n",
            "0\n",
            "128\n",
            "256\n",
            "384\n",
            "512\n",
            "640\n",
            "768\n",
            "896\n",
            "0\n",
            "128\n",
            "256\n",
            "384\n",
            "512\n",
            "640\n",
            "768\n",
            "896\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30tUpRQtq1fb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "\n",
        "def write_gazeta_records(records, file_name):\n",
        "    with open(file_name, \"w\") as w:\n",
        "        for record in records:\n",
        "            record[\"oracle_sentences\"] = list(record[\"oracle_sentences\"])\n",
        "            w.write(json.dumps(record, ensure_ascii=False).strip() + \"\\n\")\n",
        "\n",
        "write_gazeta_records(ext_train_records, \"gazeta_train_with_oracle.txt\")\n",
        "write_gazeta_records(ext_val_records, \"gazeta_val_with_oracle.txt\")\n",
        "write_gazeta_records(ext_test_records, \"gazeta_test_with_oracle.txt\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YRWEfu6royg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp \"gazeta_train_with_oracle.txt\" \"drive/My Drive/gazeta_train_with_oracle.txt\"\n",
        "!cp \"gazeta_val_with_oracle.txt\" \"drive/My Drive/gazeta_val_with_oracle.txt\"\n",
        "!cp \"gazeta_test_with_oracle.txt\" \"drive/My Drive/gazeta_test_with_oracle.txt\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLSaFW5DI9xH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp \"drive/My Drive/gazeta_train_with_oracle.txt\" \"gazeta_train_with_oracle.txt\"\n",
        "!cp \"drive/My Drive/gazeta_val_with_oracle.txt\" \"gazeta_val_with_oracle.txt\"\n",
        "!cp \"drive/My Drive/gazeta_test_with_oracle.txt\" \"gazeta_test_with_oracle.txt\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CzyD29AQJHHm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ext_train_records = read_gazeta_records(\"gazeta_train_with_oracle.txt\")\n",
        "ext_val_records = read_gazeta_records(\"gazeta_val_with_oracle.txt\")\n",
        "ext_test_records = read_gazeta_records(\"gazeta_test_with_oracle.txt\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UlXXc8qUHC5m",
        "colab_type": "text"
      },
      "source": [
        "### Составление батчей"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNyxstTChK3C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "import math\n",
        "import razdel\n",
        "import torch\n",
        "import numpy as np\n",
        "from rouge import Rouge\n",
        "\n",
        "\n",
        "class BatchIterator():\n",
        "    def __init__(self, records, vocabulary, batch_size, bpe_processor, shuffle=True, lower=True, max_sentences=30, max_sentence_length=50, device=torch.device('cpu')):\n",
        "        self.records = records\n",
        "        self.num_samples = len(records)\n",
        "        self.batch_size = batch_size\n",
        "        self.bpe_processor = bpe_processor\n",
        "        self.shuffle = shuffle\n",
        "        self.batches_count = int(math.ceil(self.num_samples / batch_size))\n",
        "        self.lower = lower\n",
        "        self.rouge = Rouge()\n",
        "        self.vocabulary = vocabulary\n",
        "        self.max_sentences = max_sentences\n",
        "        self.max_sentence_length = max_sentence_length\n",
        "        self.device = device\n",
        "        \n",
        "    def __len__(self):\n",
        "        return self.batches_count\n",
        "    \n",
        "    def __iter__(self):\n",
        "        indices = np.arange(self.num_samples)\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(indices)\n",
        "\n",
        "        for start in range(0, self.num_samples, self.batch_size):\n",
        "            end = min(start + self.batch_size, self.num_samples)\n",
        "            batch_indices = indices[start:end]\n",
        "            batch_inputs = []\n",
        "            batch_outputs = []\n",
        "            max_sentence_length = 0\n",
        "            max_sentences = 0\n",
        "            batch_records = []\n",
        "            for data_ind in batch_indices:\n",
        "                record = self.records[data_ind]\n",
        "                batch_records.append(record)\n",
        "                text = record[\"text\"]\n",
        "                summary = record[\"summary\"]\n",
        "                summary = summary.lower() if self.lower else summary\n",
        "\n",
        "                if \"sentences\" not in record:\n",
        "                    sentences = [sentence.text.lower() if self.lower else sentence.text for sentence in razdel.sentenize(text)][:self.max_sentences]\n",
        "                else:\n",
        "                    sentences = record[\"sentences\"]\n",
        "                max_sentences = max(len(sentences), max_sentences)\n",
        "\n",
        "                if \"oracle_sentences\" not in record:\n",
        "                    calc_score = lambda x, y: calc_single_score(x, y, self.rouge)\n",
        "                    sentences_indicies = build_oracle_summary_greedy(text, summary, calc_score=calc_score, lower=self.lower, max_sentences=self.max_sentences)[1]\n",
        "                else:\n",
        "                    sentences_indicies = record[\"oracle_sentences\"]\n",
        "\n",
        "                inputs = [list(map(self.vocabulary.get_index, bpe_tokenize(sentence, self.bpe_processor)[:self.max_sentence_length])) for sentence in sentences]\n",
        "                max_sentence_length = max(max_sentence_length, max([len(tokens) for tokens in inputs]))\n",
        "                outputs = [int(i in sentences_indicies) for i in range(len(sentences))]\n",
        "                batch_inputs.append(inputs)\n",
        "                batch_outputs.append(outputs)\n",
        "            tensor_inputs = torch.zeros((self.batch_size, max_sentences, max_sentence_length), dtype=torch.long, device=self.device)\n",
        "            tensor_outputs = torch.zeros((self.batch_size, max_sentences), dtype=torch.float32, device=self.device)\n",
        "            for i, inputs in enumerate(batch_inputs):\n",
        "                for j, sentence_tokens in enumerate(inputs):\n",
        "                    tensor_inputs[i][j][:len(sentence_tokens)] = torch.LongTensor(sentence_tokens)\n",
        "            for i, outputs in enumerate(batch_outputs):\n",
        "                tensor_outputs[i][:len(outputs)] = torch.LongTensor(outputs)\n",
        "\n",
        "            yield {\n",
        "                'inputs': tensor_inputs,\n",
        "                'outputs': tensor_outputs,\n",
        "                'records': batch_records\n",
        "            }"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JegA9fOMsZN5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_iterator = BatchIterator(ext_train_records, vocabulary, 4, bpe_processor)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3YxUt1F5vVw5",
        "colab_type": "code",
        "outputId": "6af3bbf1-ead5-4155-af97-f363d71e2d7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683
        }
      },
      "source": [
        "for batch in train_iterator:\n",
        "    print(batch)\n",
        "    break"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'inputs': tensor([[[   54,   892, 11342,  ...,     0,     0,     0],\n",
            "         [   72,   937,   592,  ...,     0,     0,     0],\n",
            "         [ 1042,   292,    18,  ...,     0,     0,     0],\n",
            "         ...,\n",
            "         [  454,    26,   558,  ...,     0,     0,     0],\n",
            "         [    0,     0,     0,  ...,     0,     0,     0],\n",
            "         [    0,     0,     0,  ...,     0,     0,     0]],\n",
            "\n",
            "        [[ 4107, 12488,   265,  ...,     0,     0,     0],\n",
            "         [    4,   522,   326,  ...,     0,     0,     0],\n",
            "         [   22,    54,     6,  ...,    27,  6973,    25],\n",
            "         ...,\n",
            "         [  222,   185,   186,  ...,     0,     0,     0],\n",
            "         [   22,    19,  2496,  ...,     0,     0,     0],\n",
            "         [   22,  1929,    18,  ...,     0,     0,     0]],\n",
            "\n",
            "        [[   19,  3275,    19,  ...,     0,     0,     0],\n",
            "         [ 6569,  5153,   137,  ...,     0,     0,     0],\n",
            "         [   19, 13993,  5400,  ...,     0,     0,     0],\n",
            "         ...,\n",
            "         [ 1181,  1871,  8825,  ...,     0,     0,     0],\n",
            "         [ 5799,  5940,  7876,  ...,     0,     0,     0],\n",
            "         [ 1181,  1871,  7195,  ...,     0,     0,     0]],\n",
            "\n",
            "        [[    4, 14325,    44,  ...,     0,     0,     0],\n",
            "         [ 1906,  3601,     4,  ...,     0,     0,     0],\n",
            "         [ 1118,  1062,   667,  ...,   488,  4376,   218],\n",
            "         ...,\n",
            "         [    4,   277,  3706,  ...,     0,     0,     0],\n",
            "         [   72,   292,    18,  ...,     0,     0,     0],\n",
            "         [  945,     4, 14325,  ...,     0,     0,     0]]]), 'outputs': tensor([[1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 1.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 1., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]), 'records': [{'url': 'https://www.gazeta.ru/politics/2013/02/06_a_4954889.shtml', 'text': 'По данным исследования американского института «Открытое общество», 54 государства оказывали тайную помощь ЦРУ после терактов 11 сентября 2001 года в США. Более чем 200-страничный отчет фиксирует факты содержания под стражей, допросов и передачи ЦРУ подозреваемых в террористической деятельности «Аль-Каиды» и других исламистских группировок. Кроме того, некоторые страны предоставляли свои тюрьмы для содержания задержанных, а также позволяли сотрудникам ЦРУ использовать свои аэропорты для самолетов американских спецслужб для дозаправки во время транспортировки подозреваемых в терроризме. Методы, используемые сотрудниками ЦРУ в отношении подозреваемых в терроризме, многие правозащитники расценивали как пытки. Такие действия американских спецслужб были публично осуждены, в том числе действующим президентом Бараком Обамой , когда он критиковал своего соперника Джорджа Буша во время президентской предвыборной кампании 2008 года. В докладе «Открытого общества» говорится, что заключенные, без судебных решений и соответствующих документов, переводились из одних тюрем в другие. Зачастую их перевозили в те страны, в которых пытки официально не запрещены. Среди них эксперты «Открытого общества» называют Пакистан, Иорданию, Афганистан и Египет. В докладе содержится информация о 136 подозреваемых в терроризме, которые были переданы ЦРУ. На данный момент это самый большой список обвиняемых в терроризме, переданных американским спецслужбам, отмечает The New York Times. Среди 54 стран, сотрудничавших с ЦРУ, две страны из бывшего СССР — Литва и Узбекистан. Также поддержку американской разведке оказывают Великобритания, Германия, Италия, Испания и еще целый ряд европейских государств. Только Франция и Норвегия из числа крупных стран и членов НАТО не попали в этот список. В списке значится ряд азиатских стран, среди которых Иран, власти которого официально всегда занимали яростную антиамериканскую позицию. По данным авторов доклада, несколько подозреваемых в сотрудничестве с «Аль-Каидой» были арестованы на территории Ирана и выданы афганскому правительству (которое контролировалось тогда США). В документе отмечается, что этого не могло произойти без участия американской разведки. Известно, что власти шиитского Ирана крайне враждебно относятся к «Аль-Каиде», чьи боевики регулярно устраивали теракты против мусульман-шиитов на Ближнем Востоке. Также с ЦРУ после 11 сентября сотрудничали большинство стран Северной и Восточной Африки. Такие государства, как Ирландия, Исландия и Кипр, предоставляли ЦРУ свои аэропорты для дозаправки при транспортировке подозреваемых в терроризме. Россия в докладе «Открытого общества» не упомянута ни разу. От действий ЦРУ неоднократно страдали непричастные к терроризму. Так, в декабре 2012 года Европейский суд по правам человека (ЕСПЧ) признал ЦРУ ответственным за пытки в отношении гражданина Германии Халеда аль-Масри. Он был похищен в этой стране, как пояснили сотрудники спецслужб, из-за «ошибочного опознания» и был доставлен в Афганистан, где в отношении него применялись пытки. В середине 2000-х годов в прессе разразился громкий скандал из-за секретных тюрем ЦРУ, в которых после 11 сентября содержались подозреваемые в терроризме: об этом сообщали правозащитные организации. По их данным, секретные тюрьмы располагались на территории Польши, Румынии, Марокко и Египта. Правозащитники высказывали предположения о содержании подозреваемых в сотрудничестве с Аль-Каидой в изоляторах временного содержания на территории Литвы, Украины, Саудовской Аравии, Таиланда, Катара. Тогдашний президент Джордж Буш-младший был вынужден признать существование тайных тюрем, а будущий президент Обама во время предвыборной кампании пообещал их ликвидировать. После прихода к власти Обама издал соответствующий указ, а в апреле 2009 года глава ЦРУ Леон Панетта заявил, что распоряжение главы государства выполнено.', 'title': 'Государства разведывательного управления', 'summary': 'С ЦРУ тайно сотрудничали 54 страны, говорится в докладе американского института «Открытое общество». Речь идет о передаче сотрудникам американских спецслужб подозреваемых в терроризме, о пытках людей, а также об использовании территории стран для дозаправки самолетов, осуществляющих транспортировку подозреваемых в сотрудничестве с «Аль-Каидой». Среди перечисленных государств Узбекистан и Литва, а также Иран, публично всегда выступающий с антиамериканских позиций.', 'date': '2013-02-06 15:29:23', 'sentences': ['по данным исследования американского института «открытое общество», 54 государства оказывали тайную помощь цру после терактов 11 сентября 2001 года в сша.', 'более чем 200-страничный отчет фиксирует факты содержания под стражей, допросов и передачи цру подозреваемых в террористической деятельности «аль-каиды» и других исламистских группировок.', 'кроме того, некоторые страны предоставляли свои тюрьмы для содержания задержанных, а также позволяли сотрудникам цру использовать свои аэропорты для самолетов американских спецслужб для дозаправки во время транспортировки подозреваемых в терроризме.', 'методы, используемые сотрудниками цру в отношении подозреваемых в терроризме, многие правозащитники расценивали как пытки.', 'такие действия американских спецслужб были публично осуждены, в том числе действующим президентом бараком обамой , когда он критиковал своего соперника джорджа буша во время президентской предвыборной кампании 2008 года.', 'в докладе «открытого общества» говорится, что заключенные, без судебных решений и соответствующих документов, переводились из одних тюрем в другие.', 'зачастую их перевозили в те страны, в которых пытки официально не запрещены.', 'среди них эксперты «открытого общества» называют пакистан, иорданию, афганистан и египет.', 'в докладе содержится информация о 136 подозреваемых в терроризме, которые были переданы цру.', 'на данный момент это самый большой список обвиняемых в терроризме, переданных американским спецслужбам, отмечает the new york times.', 'среди 54 стран, сотрудничавших с цру, две страны из бывшего ссср — литва и узбекистан.', 'также поддержку американской разведке оказывают великобритания, германия, италия, испания и еще целый ряд европейских государств.', 'только франция и норвегия из числа крупных стран и членов нато не попали в этот список.', 'в списке значится ряд азиатских стран, среди которых иран, власти которого официально всегда занимали яростную антиамериканскую позицию.', 'по данным авторов доклада, несколько подозреваемых в сотрудничестве с «аль-каидой» были арестованы на территории ирана и выданы афганскому правительству (которое контролировалось тогда сша).', 'в документе отмечается, что этого не могло произойти без участия американской разведки.', 'известно, что власти шиитского ирана крайне враждебно относятся к «аль-каиде», чьи боевики регулярно устраивали теракты против мусульман-шиитов на ближнем востоке.', 'также с цру после 11 сентября сотрудничали большинство стран северной и восточной африки.', 'такие государства, как ирландия, исландия и кипр, предоставляли цру свои аэропорты для дозаправки при транспортировке подозреваемых в терроризме.', 'россия в докладе «открытого общества» не упомянута ни разу.', 'от действий цру неоднократно страдали непричастные к терроризму.', 'так, в декабре 2012 года европейский суд по правам человека (еспч) признал цру ответственным за пытки в отношении гражданина германии халеда аль-масри.', 'он был похищен в этой стране, как пояснили сотрудники спецслужб, из-за «ошибочного опознания» и был доставлен в афганистан, где в отношении него применялись пытки.', 'в середине 2000-х годов в прессе разразился громкий скандал из-за секретных тюрем цру, в которых после 11 сентября содержались подозреваемые в терроризме: об этом сообщали правозащитные организации.', 'по их данным, секретные тюрьмы располагались на территории польши, румынии, марокко и египта.', 'правозащитники высказывали предположения о содержании подозреваемых в сотрудничестве с аль-каидой в изоляторах временного содержания на территории литвы, украины, саудовской аравии, таиланда, катара.', 'тогдашний президент джордж буш-младший был вынужден признать существование тайных тюрем, а будущий президент обама во время предвыборной кампании пообещал их ликвидировать.', 'после прихода к власти обама издал соответствующий указ, а в апреле 2009 года глава цру леон панетта заявил, что распоряжение главы государства выполнено.'], 'oracle_sentences': [0, 2, 8, 14, 17], 'oracle_summary': 'по данным исследования американского института «открытое общество», 54 государства оказывали тайную помощь цру после терактов 11 сентября 2001 года в сша. кроме того, некоторые страны предоставляли свои тюрьмы для содержания задержанных, а также позволяли сотрудникам цру использовать свои аэропорты для самолетов американских спецслужб для дозаправки во время транспортировки подозреваемых в терроризме. в докладе содержится информация о 136 подозреваемых в терроризме, которые были переданы цру. по данным авторов доклада, несколько подозреваемых в сотрудничестве с «аль-каидой» были арестованы на территории ирана и выданы афганскому правительству (которое контролировалось тогда сша). также с цру после 11 сентября сотрудничали большинство стран северной и восточной африки.'}, {'url': 'https://www.gazeta.ru/sport/2012/08/01/a_4706337.shtml', 'text': 'Перед матчем с голландским «Витессом» наставник «Анжи» Гус Хиддинк ответил на вопросы журналистов. «Мы очень рады играть на этой стадии отборочного турнира, — начал голландский тренер. — По итогам прошлого чемпионата России мы заняли пятое место, попали во второй отборочный раунд Лиги Европы, прошли его, теперь уже третий, надеемся, что и его пройдем успешно, потому что мы хотим дальше пройти в этом турнире. На этой стадии с нами сыграет команда, которую возглавляет мой бывший коллега — напарник по ПСВ Фред Рюттен, с которым мы много лет работали бок о бок, поэтому для меня это тоже особенный момент». «Анжи» (Махачкала, Россия) — «Витесс» (Арнем, Нидерланды) 2 августа, четверг, 19.00 Раменское, «Сатурн» Судья: Рудди Буке (Франция) Котировки БК «Марафон» на вечер среды: 1.444 — 4.55 — 7.70 — Что вы думаете о том имиджевом скачке, что совершил «Анжи» в последнее время? — «Анжи» все-таки только начинает свои шаги в европейском футболе, несмотря на то, что в истории клуба уже имеется факт участия в еврокубках. Поэтому, я думаю, что сегодня мы не находимся в числе тех команд, которые регулярно играют в европейских кубках и уже сделали себе имя, но мы, безусловно, хотим попасть в их число. Мы будем стараться выстраивать постепенно профессиональную структуру организации, работу клуба, команды. Если взять состав нашей команды, то средний возраст ее составляет 23,9 лет. Это говорит о том, что «Анжи» — не тот клуб, который просто покупает и покупает дорогостоящих игроков, но также думает о будущем. Мы вкладываемся в хороших молодых российских футболистов, которые могут принести пользу команде в будущем. То есть мы покупаем хороших футболистов, а также инвестируем в будущее — развиваем молодых. — Учитывая, что в «Анжи» большая голландская диаспора, можно сказать, что игра получится для тренерского штаба домашней? — На самом деле, не так уж много голландцев у нас в клубе. Да, они есть, но они полурусские — полуголландцы. На самом деле, мы не проводим большого различия между иностранцами и русскими, а тот факт, что нам предстоит играть против голландской команды — да, это придает какой-то оттенок этому матчу. Особенно учитывая тот факт, что, как я сказал уже, командой руководит мой бывший помощник. Мне интересно будет сыграть против него. — На эмблемах «Анжи» и «Витесса» изображены орлы. Завтра дагестанский орел заклюет голландского? — Я об этом не думал, но это действительно так. Думаю, дагестанский орел будет покрупнее голландского при всем уважении к тому, что они сделали за последнее время. Также на домашнем стадионе «Витесса», по-моему, они выпускают живого орла, поэтому можно тоже будет посмотреть на это. Но все же я надеюсь, что дагестанский орел будет сильнее. — Сегодня был оглашен расширенный состав национальной команды России, в который вошли сразу три молодых игрока вашей команды — Шатов, Смолов, Логашов. — Да, это связано именно с тем, о чем я говорил ранее. Это вознаграждение и игрокам, и клубу, который проводит такую стратегию — это хороший признак. И если они попадут в окончательный состав, то это будет еще большее вознаграждение. — В матче с «Ростовом» «Анжи» играл десятью игроками, потратил очень много сил, сумеет ли команда восстановиться к завтрашнему матчу? — Да, действительно было очень сложно в том матче. Мы получили две красные карточки, но в целом, мне понравилось, как команда отреагировала, даже забила гол и повела в счете. Но мне не хотелось бы жаловаться на плотный график — это именно то, чего мы хотели, когда выходили в еврокубки. Хотя, я думаю, у нас немного была смазана подготовка к сезону из-за того, что многие игроки уезжали в свои сборные. В частности та травма, которую получил Ласина Траоре. Но в принципе у нас есть хороший баланс в команде, все игроки хорошо восстанавливаются. Также вместе с Хиддинком на предматчевую пресс-конференцию пришел директор клуба Роберто Карлос. Он отметил, что соперники махачкалинской команды в Лиге Европы с каждым раундом все сильнее. «Соперники у «Анжи» с каждым раундом становятся все сильнее, — отметил Карлос. — «Витесс» – очень хорошая команда. В принципе, она нам знакома. В эмоциональном плане мы тоже достаточно хорошо готовы. Сейчас нам надо удачно сыграть в домашнем матче, чтобы на выезде иметь преимущество». Хиддинк объяснил, почему вместе с ним не пришел кто-то из игроков команды. Наставник махачкалинцев заявил, что пришло время официально объявить, что бразилец больше не является игроком «Анжи». «К сожалению, он больше не действующий игрок нашей команды, — сказал Хиддинк. -— Рано или поздно любая карьера заканчивается. Я думаю, что его харизма и авторитет принесут большую пользу в плане продвижения имиджа клуба на мировой и европейской арене, я надеюсь, что клуб будет часто участвовать в европейских турнирах, а также внесет вклад в продвижение всего российского футбола». Бразилец поведал, что в настоящее время ведутся переговоры с руководством мадридского «Реала» о проведении Карлосом прощального матча. «Мы недавно разговаривали с президентом «Реала» Флорентино Пересем, — рассказал он. — Сейчас мы договариваемся о том, чтобы провести мой прощальный матч. Надеюсь, что он пройдет на территории Дагестана». Ознакомиться с другими материалами, новостями и статистикой можно на странице Лиги Европы.', 'title': '«Дагестанский орел сильнее голландского»', 'summary': 'Главный тренер «Анжи» Гус Хиддинк в преддверии матча Лиги Европы против голландского «Витесса» рассказал об ожиданиях команды, заявив, что надеется пройти с «Анжи» как можно дальше по турнирному пути Лиги Европы. Роберто Карлос сообщил, что его прощальный матч с футболистами «Реала» может пройти на территории Дагестана.', 'date': '2012-08-01 20:43:05', 'sentences': ['перед матчем с голландским «витессом» наставник «анжи» гус хиддинк ответил на вопросы журналистов.', '«мы очень рады играть на этой стадии отборочного турнира, — начал голландский тренер.', '— по итогам прошлого чемпионата россии мы заняли пятое место, попали во второй отборочный раунд лиги европы, прошли его, теперь уже третий, надеемся, что и его пройдем успешно, потому что мы хотим дальше пройти в этом турнире.', 'на этой стадии с нами сыграет команда, которую возглавляет мой бывший коллега — напарник по псв фред рюттен, с которым мы много лет работали бок о бок, поэтому для меня это тоже особенный момент».', '«анжи» (махачкала, россия) — «витесс» (арнем, нидерланды) 2 августа, четверг, 19.00 раменское, «сатурн» судья: рудди буке (франция) котировки бк «марафон» на вечер среды: 1.444 — 4.55 — 7.70 — что вы думаете о том имиджевом скачке, что совершил «анжи» в последнее время?', '— «анжи» все-таки только начинает свои шаги в европейском футболе, несмотря на то, что в истории клуба уже имеется факт участия в еврокубках.', 'поэтому, я думаю, что сегодня мы не находимся в числе тех команд, которые регулярно играют в европейских кубках и уже сделали себе имя, но мы, безусловно, хотим попасть в их число.', 'мы будем стараться выстраивать постепенно профессиональную структуру организации, работу клуба, команды.', 'если взять состав нашей команды, то средний возраст ее составляет 23,9 лет.', 'это говорит о том, что «анжи» — не тот клуб, который просто покупает и покупает дорогостоящих игроков, но также думает о будущем.', 'мы вкладываемся в хороших молодых российских футболистов, которые могут принести пользу команде в будущем.', 'то есть мы покупаем хороших футболистов, а также инвестируем в будущее — развиваем молодых.', '— учитывая, что в «анжи» большая голландская диаспора, можно сказать, что игра получится для тренерского штаба домашней?', '— на самом деле, не так уж много голландцев у нас в клубе.', 'да, они есть, но они полурусские — полуголландцы.', 'на самом деле, мы не проводим большого различия между иностранцами и русскими, а тот факт, что нам предстоит играть против голландской команды — да, это придает какой-то оттенок этому матчу.', 'особенно учитывая тот факт, что, как я сказал уже, командой руководит мой бывший помощник.', 'мне интересно будет сыграть против него.', '— на эмблемах «анжи» и «витесса» изображены орлы.', 'завтра дагестанский орел заклюет голландского?', '— я об этом не думал, но это действительно так.', 'думаю, дагестанский орел будет покрупнее голландского при всем уважении к тому, что они сделали за последнее время.', 'также на домашнем стадионе «витесса», по-моему, они выпускают живого орла, поэтому можно тоже будет посмотреть на это.', 'но все же я надеюсь, что дагестанский орел будет сильнее.', '— сегодня был оглашен расширенный состав национальной команды россии, в который вошли сразу три молодых игрока вашей команды — шатов, смолов, логашов.', '— да, это связано именно с тем, о чем я говорил ранее.', 'это вознаграждение и игрокам, и клубу, который проводит такую стратегию — это хороший признак.', 'и если они попадут в окончательный состав, то это будет еще большее вознаграждение.', '— в матче с «ростовом» «анжи» играл десятью игроками, потратил очень много сил, сумеет ли команда восстановиться к завтрашнему матчу?', '— да, действительно было очень сложно в том матче.'], 'oracle_sentences': [0], 'oracle_summary': 'перед матчем с голландским «витессом» наставник «анжи» гус хиддинк ответил на вопросы журналистов.'}, {'url': 'https://www.gazeta.ru/sport/2012/07/28/a_4700405.shtml', 'text': 'В субботу в Лондоне стартовал теннисный турнир XXX летних Олимпийских игр. Матчи проходят на травяных кортах Уимблдона, завершившего месяц назад свой открытый чемпионат. В женской сетке Россиянка Вера Звонарева (13) начала свой турнирный путь с победы над Софией Арвидссон со счетом 7:6 (7:3), 6:4. Следующей соперницей россиянки станет победительница пары Франческа Скьявоне (Италия), обыгравшая Клару Закопалову (Чехия) со счетом 6:3, 3:6, 6:4. «Здесь легких матчей не будет, это Олимпиада, и состав участников говорит сам за себя, — передает слова Звонаревой РИА «Новости». — Для меня победа в напряженной борьбе сейчас даже бонус, потому что хочется побольше поиграть на траве, все-таки мы очень редко выступаем на этом покрытии». Женщины. Одиночный разряд. 1-й круг Вера Звонарева (Россия, 13) - София Арвидссон (Швеция) - 7:6 (3), 6:4 Мужчины. Одиночный разряд. 1-й круг Жюльен Беннето (Франция) - Михаил Южный (Россия) - 7:5, 6:3 Алекс Богомолов (Россия) - Карлос Берлок (Аргентина) - 7:5, 7:6 (5) Женищины. Парный разряд. 1-й круг Мария Кириленко / Надежда Петрова (Россия, 3) - Клаудия Янс / Алиция Росольска (Польша) - 6:7 (5), 6:3, 6:2 Елена Веснина / Екатерина Макарова (Россия, 6) - Ярмила Гайдошова / Анастасия Родионова (Австралия) - 6:1, 6:4 Также Звонарева рассказала, что к своему самочувствию у нее претензий нет, и о бронхите, из-за которого ей пришлось сняться месяц назад с Уимблдонского турнира, не осталось даже воспоминаний. «Я чувствую себя хорошо. Восстановилась полностью, — подчеркнула она. — Жалко, что две недели пришлось пропустить, я вообще не тренировалась, потом тяжело было возвращаться. Так что форму не совсем еще набрала, но это не страшно — здесь один матч уже выиграть удалось, нужно готовиться дальше. Завтра день отдыха, есть возможность потренироваться, так что, надеюсь, буду только прибавлять». Сербка Ана Иванович (11) переиграла американку Кристину Макхэйл со счётом 6:4, 7:5. Следующей соперницей Иванович станет британка Елена Балтача (WC), переигравшая венгерку Агнеш Саваи. Бельгийка Ким Клейстерс в первом матче играла с итальянкой Робертой Винчи и победила со счётом 6:1, 6:4. За выход в третий круг соревнований Клейстерс поспорит с испанкой Анабель Медина-Гарригес, которая на старте сломила сопротивление австралийки Саманты Стосур. «Я чувствую себя хорошо физически и как прежде ощущаю, что могу обыграть здесь много хороших и сильных теннисисток, — сказала Клейстерс. — Олимпийские игры — особенный турнир, а для меня эта особенность заключается еще и в том, что это мои предпоследние соревнования. На Играх многие привычные вещи воспринимаются совсем иначе, здесь все происходит как-то по-другому. Я счастлива, что за 15 лет в туре я могу еще находить что-то новое для себя, и это чудесно». Американка Серена Уильямс (4) в своем матче оказалась сильнее сербки Елены Янкович , обыграв ее со счётом 6:3, 6:1. Во втором круге американка сыграет с Урсулой Радваньской из Польши. Чешка Петра Квитова с трудом вышла во второй круг, обыграв со счётом 6:4, 5:7, 6:4 украинку Катерину Бондаренко. Во втором раунде встретится с китаянкой Пэн Шуай, обыгравшей в своем стартовом матче представительницу Тайвани Хсиех Су-Вей. В мужской сетке россиянин Михаил Южный проиграл свой стартовый матч французу Жюльену Беннето со счетом 5:7, 3:6. Тренерский штаб российской команды связывал основные надежды в соревнованиях у мужчин именно с Южным, дошедшим на Уимблдоне до четвертьфинала. Таким образом, один российский теннисист закончил свое выступление в одиночном разряде. Еще один россиянин Алекс Богомолов смог пройти стартовый рубеж турнира, обыграв аргентинца Карлоса Берлока со счетом 7:5, 7:6 (5). Его следующим соперником станет испанец Николас Альмагро (11), который, в свою очередь, переиграл француза Решара Гаске. Между тем, первую сенсацию турнира преподнес чех Томаш Бердых , посеянный под шестым номером, в первом круге неожиданно проигравший бельгийцу Стиву Дарси со счётом 4:6, 4:6. В следующем круге соперником бельгийца станет колумбиец Сантьяго Хиральдо, обыгравший американца Райана Харрисона со счётом 7:5, 6:3. Первая ракетка мира швейцарец Роджер Федерер в трех сетах обыграл колумбийца Алехандро Фалью со счетом 6:3, 5:7, 6:3 и во втором круге встретится с обидчиком Южного Беннето. В парном разряде у женщин два российских дуэта вышли в следующий круг. Елена Веснина / Екатерина Макарова одержали победу над австралийками Ярмилой Гайдошовой и Анастасией Родионовой со счетом 6:1, 6:4. Соперницами россиянок по следующему кругу станет победитель противостояния Елена Балтача/ Энн Кеотавонг (Великобритания) — Юлия Гёргес/ Анна-Лена Грёнефельд (Германия). «Конечно, перед матчем было небольшое волнение, потому что для меня это первая Олимпиада, и очень хочется хорошо тут сыграть, — сказала Екатерина Макарова РИА «Новости». — Но мы с Весниной хорошо были сыграны, долго тренировали до Олимпиады и чувствовали, что чисто сыграли, не было глупых ошибок. В первом сете дисциплинированно сыграли. Во втором сете была пара моментов, когда мы могли чуть раньше брейкануть, но не сделали этого. Хорошо, что все закончилось в нашу пользу». «Мы все вчетвером волновались, но просто мы с Катей чуть лучше справились с волнением, — отметила Веснина. — Я считаю, что нам нужно еще добавлять, работать над своим уровнем игры, над многими другими техническими аспектами, не останавливаться, идти вперед и стараться совершенствоваться». В свою очередь, Мария Кириленко и Надежда Петрова одолели полячек Клаудию Янс и Алицию Росольску со счетом 6:7 (5), 6:3, 6:2. В следующем матче россиянки сыграют с казахстанской парой Ярослава Шведова / Галина Воскобоева. «Действительно была немного напряженная игра сегодня, все-таки первая игра, Олимпиада, ощущения немного другие, чем на обычном турнире, чувствовалась ответственность, может быть, поэтому вначале немного не получалось, — сказала Кириленко РИА «Новости». — Тем не менее, мы вели в первом сете, правда, потом его проиграли. Но стоит отметить, что девчонки очень удачно начали играть, очень много у них было мячей, которые они выиграли наудачу, и как-то так они переломили нас. Но все равно, проиграв первый сет, мы понимали, что мы лучше, мы лидеры и должны победить». «Может быть, на Играх дополнительное давление и есть, так как хочется показать, на что ты способен, – сказала Петрова. – Посложнее приходится на Олимпиаде, чем на обычных турнирах. Так как Игры бывают лишь раз в четыре года, то понимаешь, что это может быть раз или два за твою карьеру, поэтому волнение есть, чувствуется ответственность, на матчи приходят все официальные лица, тренеры». Ознакомиться с другими материалами, новостями и статистикой можно на странице Олимпиады-2012.', 'title': 'Звонарева стартовала с победы', 'summary': 'Вера Звонарева начала олимпийский теннисный турнир с победы, Михаил Южный закончил выступление на Ирах, а Алекс Богомолов пробился в следующий круг. Томаш Бердых сенсационно проиграл бельгийцу Дарси.', 'date': '2012-07-28 22:49:52', 'sentences': ['в субботу в лондоне стартовал теннисный турнир xxx летних олимпийских игр.', 'матчи проходят на травяных кортах уимблдона, завершившего месяц назад свой открытый чемпионат.', 'в женской сетке россиянка вера звонарева (13) начала свой турнирный путь с победы над софией арвидссон со счетом 7:6 (7:3), 6:4.', 'следующей соперницей россиянки станет победительница пары франческа скьявоне (италия), обыгравшая клару закопалову (чехия) со счетом 6:3, 3:6, 6:4.', '«здесь легких матчей не будет, это олимпиада, и состав участников говорит сам за себя, — передает слова звонаревой риа «новости».', '— для меня победа в напряженной борьбе сейчас даже бонус, потому что хочется побольше поиграть на траве, все-таки мы очень редко выступаем на этом покрытии».', 'женщины.', 'одиночный разряд.', '1-й круг вера звонарева (россия, 13) - софия арвидссон (швеция) - 7:6 (3), 6:4 мужчины.', 'одиночный разряд.', '1-й круг жюльен беннето (франция) - михаил южный (россия) - 7:5, 6:3 алекс богомолов (россия) - карлос берлок (аргентина) - 7:5, 7:6 (5) женищины.', 'парный разряд.', '1-й круг мария кириленко / надежда петрова (россия, 3) - клаудия янс / алиция росольска (польша) - 6:7 (5), 6:3, 6:2 елена веснина / екатерина макарова (россия, 6) - ярмила гайдошова / анастасия родионова (австралия) - 6:1, 6:4 также звонарева рассказала, что к своему самочувствию у нее претензий нет, и о бронхите, из-за которого ей пришлось сняться месяц назад с уимблдонского турнира, не осталось даже воспоминаний.', '«я чувствую себя хорошо.', 'восстановилась полностью, — подчеркнула она.', '— жалко, что две недели пришлось пропустить, я вообще не тренировалась, потом тяжело было возвращаться.', 'так что форму не совсем еще набрала, но это не страшно — здесь один матч уже выиграть удалось, нужно готовиться дальше.', 'завтра день отдыха, есть возможность потренироваться, так что, надеюсь, буду только прибавлять».', 'сербка ана иванович (11) переиграла американку кристину макхэйл со счётом 6:4, 7:5.', 'следующей соперницей иванович станет британка елена балтача (wc), переигравшая венгерку агнеш саваи.', 'бельгийка ким клейстерс в первом матче играла с итальянкой робертой винчи и победила со счётом 6:1, 6:4.', 'за выход в третий круг соревнований клейстерс поспорит с испанкой анабель медина-гарригес, которая на старте сломила сопротивление австралийки саманты стосур.', '«я чувствую себя хорошо физически и как прежде ощущаю, что могу обыграть здесь много хороших и сильных теннисисток, — сказала клейстерс.', '— олимпийские игры — особенный турнир, а для меня эта особенность заключается еще и в том, что это мои предпоследние соревнования.', 'на играх многие привычные вещи воспринимаются совсем иначе, здесь все происходит как-то по-другому.', 'я счастлива, что за 15 лет в туре я могу еще находить что-то новое для себя, и это чудесно».', 'американка серена уильямс (4) в своем матче оказалась сильнее сербки елены янкович , обыграв ее со счётом 6:3, 6:1.', 'во втором круге американка сыграет с урсулой радваньской из польши.', 'чешка петра квитова с трудом вышла во второй круг, обыграв со счётом 6:4, 5:7, 6:4 украинку катерину бондаренко.', 'во втором раунде встретится с китаянкой пэн шуай, обыгравшей в своем стартовом матче представительницу тайвани хсиех су-вей.'], 'oracle_sentences': [0, 8, 10], 'oracle_summary': 'в субботу в лондоне стартовал теннисный турнир xxx летних олимпийских игр. 1-й круг вера звонарева (россия, 13) - софия арвидссон (швеция) - 7:6 (3), 6:4 мужчины. 1-й круг жюльен беннето (франция) - михаил южный (россия) - 7:5, 6:3 алекс богомолов (россия) - карлос берлок (аргентина) - 7:5, 7:6 (5) женищины.'}, {'url': 'https://www.gazeta.ru/business/2018/10/10/12016117.shtml', 'text': '«Нафтогаз» не устает искать способы хоть что-то получить с «Газпрома». Теперь украинский «партнер» российского газового монополиста решил удержать $9 млн, которые «Газпром» переплатил за транзит газа через газотранспортную систему (ГТС) Украины. Свои действия компания объяснила так: «Сегодня НАК «Нафтогаз Украины» направила ОАО «Газпром» заявление о зачислении переплат за транзит газа в счет погашения пени, которая начисляется на задолженность российского монополиста согласно арбитражному решению от 28 февраля 2018 по транзитному контракту». Речь идет о решениях Стокгольмского арбитража по поставке и транзите газа. По итогам взаимных исков «Газпром» оказался должен «Нафтогазу» $2,56 млрд. Российская компания подала апелляционную жалобу в суд шведского округа Свеа, а «Нафтогаз» включил счетчик. Как пишет украинская компания в своем заявлении, «на сегодня размер начисленной пени составляет более $100 млн». Последовательно отказываясь выполнять решение Стокгольмского арбитража, «Газпром» в 2018 году продолжает платить за транзит большую цену, чем выставляет «Нафтогаз», который рассчитывает тариф в соответствии с решением арбитража. За август образовалась переплата в $9 млн, именно она и была засчитана как платеж в исполнение арбитражного решения, поясняют в украинской компании. Это не первая попытка «Нафтогаза» любым способом призвать «Газпром» к ответу. Зарубежные активы «Газпрома», в частности в Нидерландах, Швейцарии и Великобритании, подвергаются аресту по требованиям Украины. Речь идет в том числе о компаниях Nord Stream AG и Nord Stream 2 AG — операторах действующего газопровода «Северный поток» и строящегося «Северный поток — 2». Эксперты уверены, что такие действия «Нафтогаза» только осложнят и без того непростые отношения между сторонами газового конфликта, а Россия сможет оспорить действия Украины. Технически речь идет не о направлении средств на погашение имеющегося долга, а об отказе возврата средств, полученных в результате переплаты за услуги транзита газа по действующему до конца 2019 года контракту, поясняет управляющий партнер Экспертной группы Veta Илья Жарский. Не обладая функциями судебной или исполнительной власти, НАК «Нафтогаз» не имеет полномочий принимать решения об обращении собственных требований на выплаченные ей «Газпромом» средства. «Следовательно, со своей стороны «Газпром» имеет все основания требовать возврата средств за услуги, которые были выплачены за непредоставленные ему услуги, что соответствует договору, который стороны обязались исполнять. Если средства не будут возвращены в полном объеме, это даст «Газпрому» право требовать их в судебном порядке и создает повод обвинить «Нафтогаз» в неосновательном обогащении», — считает он. «Если пени были прописаны в договоре, то, разумеется, «Нафтогаз» имеет на них право, однако «Нафтогаз» является коммерческим агентом «Газпрома», а не наоборот, и в этом заключена конечная правда всей этой многомесячной неприглядной истории», — обращает внимание эксперт «Международного финансового центра» Владимир Рожанковский. «Забрав сиюминутно себе все причитающееся — зачастую опережая решения арбитражного суда — «Нафтогаз» постепенно утрачивает перспективу продолжения партнерских отношений с «Газпромом», а альтернатив-то у него нет», — добавляет он. Между тем это всего лишь один штрих в этой истории. Летом «Нафтогаз» подал еще один иск против «Газпрома» с требованием пересмотреть тариф на транзит газа с марта 2018 года. Свои требования украинская компания тогда оценила в $11,59 млрд. При том, что действующий контракт истекает в 2019 году, а другой стороны не могут заключить, так как даже трехсторонние переговоры с привлечение Еврокомиссии и экспертов результатов пока не дали. Усугубляется положение Киева в данном споре тем, что в 2020 году «Газпром» рассчитывает запустить «Северный поток — 2», который по факту «заберет» на себя порядка 55 млрд кубометров транзитной прокачки, которая сейчас идет через украинскую ГТС. Еще около 35 млрд куб м перейдет на «Турецкий поток», который предполагается запустить в 2020 году. Всего по украинской ГТС сейчас проходит около 90 млрд куб м газа из РФ в европейском направлении, а после запуска этих проектов РФ может серьезно снизить, если не вовсе сократить этот объем. Мирное решение спора предлагал ранее президент РФ Владимир Путин на пресс-конференции после встречи с президентом США Дональдом Трампом. « Россия готова сохранить этот транзит. Более того, мы готовы продлить транзитный контракт, который истекает в следующем году, в случае урегулирования спора между хозяйствующими субъектами в Стокгольмском арбитражном суде», — сказал Путин. Однако «Нафтогаз» не может сейчас на это согласиться: слишком часто с больших трибун выражали радость от победы на «Газпромом», слишком быстро менеджеры «Нафтогаза» выписали себе премии после арбитражного решения. В преддверии выборов президента и парламента, которые пройдут в следующем году, Киев едва ли пойдет на компромисс.', 'title': 'Разбой по-соседски: «Нафтогаз» забрал у «Газпрома» $9 млн', 'summary': '«Нафтогаз Украины» забрал себе переплату «Газпрома» в $9 млн по транзитному контракту. Эти деньги пойдут в счет $2,56 млрд, которые, по решению Стокгольмского арбитража, российская компания должна выплатить украинской стороне. В «Нафтогазе» напомнили, что за каждый день просрочки начисляется пеня — она уже достигла $100 млн. Юристы считают, что Украина не имела права забирать эти деньги и «Газпром» сможет оспорить это решение.', 'date': '2018-10-10 20:14:44', 'sentences': ['«нафтогаз» не устает искать способы хоть что-то получить с «газпрома».', 'теперь украинский «партнер» российского газового монополиста решил удержать $9 млн, которые «газпром» переплатил за транзит газа через газотранспортную систему (гтс) украины.', 'свои действия компания объяснила так: «сегодня нак «нафтогаз украины» направила оао «газпром» заявление о зачислении переплат за транзит газа в счет погашения пени, которая начисляется на задолженность российского монополиста согласно арбитражному решению от 28 февраля 2018 по транзитному контракту».', 'речь идет о решениях стокгольмского арбитража по поставке и транзите газа.', 'по итогам взаимных исков «газпром» оказался должен «нафтогазу» $2,56 млрд.', 'российская компания подала апелляционную жалобу в суд шведского округа свеа, а «нафтогаз» включил счетчик.', 'как пишет украинская компания в своем заявлении, «на сегодня размер начисленной пени составляет более $100 млн».', 'последовательно отказываясь выполнять решение стокгольмского арбитража, «газпром» в 2018 году продолжает платить за транзит большую цену, чем выставляет «нафтогаз», который рассчитывает тариф в соответствии с решением арбитража.', 'за август образовалась переплата в $9 млн, именно она и была засчитана как платеж в исполнение арбитражного решения, поясняют в украинской компании.', 'это не первая попытка «нафтогаза» любым способом призвать «газпром» к ответу.', 'зарубежные активы «газпрома», в частности в нидерландах, швейцарии и великобритании, подвергаются аресту по требованиям украины.', 'речь идет в том числе о компаниях nord stream ag и nord stream 2 ag — операторах действующего газопровода «северный поток» и строящегося «северный поток — 2».', 'эксперты уверены, что такие действия «нафтогаза» только осложнят и без того непростые отношения между сторонами газового конфликта, а россия сможет оспорить действия украины.', 'технически речь идет не о направлении средств на погашение имеющегося долга, а об отказе возврата средств, полученных в результате переплаты за услуги транзита газа по действующему до конца 2019 года контракту, поясняет управляющий партнер экспертной группы veta илья жарский.', 'не обладая функциями судебной или исполнительной власти, нак «нафтогаз» не имеет полномочий принимать решения об обращении собственных требований на выплаченные ей «газпромом» средства.', '«следовательно, со своей стороны «газпром» имеет все основания требовать возврата средств за услуги, которые были выплачены за непредоставленные ему услуги, что соответствует договору, который стороны обязались исполнять.', 'если средства не будут возвращены в полном объеме, это даст «газпрому» право требовать их в судебном порядке и создает повод обвинить «нафтогаз» в неосновательном обогащении», — считает он.', '«если пени были прописаны в договоре, то, разумеется, «нафтогаз» имеет на них право, однако «нафтогаз» является коммерческим агентом «газпрома», а не наоборот, и в этом заключена конечная правда всей этой многомесячной неприглядной истории», — обращает внимание эксперт «международного финансового центра» владимир рожанковский.', '«забрав сиюминутно себе все причитающееся — зачастую опережая решения арбитражного суда — «нафтогаз» постепенно утрачивает перспективу продолжения партнерских отношений с «газпромом», а альтернатив-то у него нет», — добавляет он.', 'между тем это всего лишь один штрих в этой истории.', 'летом «нафтогаз» подал еще один иск против «газпрома» с требованием пересмотреть тариф на транзит газа с марта 2018 года.', 'свои требования украинская компания тогда оценила в $11,59 млрд.', 'при том, что действующий контракт истекает в 2019 году, а другой стороны не могут заключить, так как даже трехсторонние переговоры с привлечение еврокомиссии и экспертов результатов пока не дали.', 'усугубляется положение киева в данном споре тем, что в 2020 году «газпром» рассчитывает запустить «северный поток — 2», который по факту «заберет» на себя порядка 55 млрд кубометров транзитной прокачки, которая сейчас идет через украинскую гтс.', 'еще около 35 млрд куб м перейдет на «турецкий поток», который предполагается запустить в 2020 году.', 'всего по украинской гтс сейчас проходит около 90 млрд куб м газа из рф в европейском направлении, а после запуска этих проектов рф может серьезно снизить, если не вовсе сократить этот объем.', 'мирное решение спора предлагал ранее президент рф владимир путин на пресс-конференции после встречи с президентом сша дональдом трампом.', '« россия готова сохранить этот транзит.', 'более того, мы готовы продлить транзитный контракт, который истекает в следующем году, в случае урегулирования спора между хозяйствующими субъектами в стокгольмском арбитражном суде», — сказал путин.', 'однако «нафтогаз» не может сейчас на это согласиться: слишком часто с больших трибун выражали радость от победы на «газпромом», слишком быстро менеджеры «нафтогаза» выписали себе премии после арбитражного решения.'], 'oracle_sentences': [2, 5, 7, 8, 12], 'oracle_summary': 'свои действия компания объяснила так: «сегодня нак «нафтогаз украины» направила оао «газпром» заявление о зачислении переплат за транзит газа в счет погашения пени, которая начисляется на задолженность российского монополиста согласно арбитражному решению от 28 февраля 2018 по транзитному контракту». российская компания подала апелляционную жалобу в суд шведского округа свеа, а «нафтогаз» включил счетчик. последовательно отказываясь выполнять решение стокгольмского арбитража, «газпром» в 2018 году продолжает платить за транзит большую цену, чем выставляет «нафтогаз», который рассчитывает тариф в соответствии с решением арбитража. за август образовалась переплата в $9 млн, именно она и была засчитана как платеж в исполнение арбитражного решения, поясняют в украинской компании. эксперты уверены, что такие действия «нафтогаза» только осложнят и без того непростые отношения между сторонами газового конфликта, а россия сможет оспорить действия украины.'}]}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4q2Gb6ODHHB_",
        "colab_type": "text"
      },
      "source": [
        "### Обучение"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5ZApHkw2Jq-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import time\n",
        "\n",
        "def train_model(model, train_records, val_records, vocabulary, bpe_processor, batch_size=32,\n",
        "                epochs_count=10, loss_every_nsteps=16, lr=0.001, device_name=\"cuda\"):\n",
        "    params_count = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    print(\"Trainable params: {}\".format(params_count))\n",
        "    device = torch.device(device_name)\n",
        "    model = model.to(device)\n",
        "    total_loss = 0\n",
        "    start_time = time.time()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "    loss_function = nn.BCEWithLogitsLoss().to(device)\n",
        "    for epoch in range(epochs_count):\n",
        "        for step, batch in enumerate(BatchIterator(train_records, vocabulary, batch_size, bpe_processor, device=device)):\n",
        "            model.train()\n",
        "            logits = model(batch[\"inputs\"]) # Прямой проход\n",
        "            loss = loss_function(logits, batch[\"outputs\"]) # Подсчёт ошибки\n",
        "            loss.backward() # Подсчёт градиентов dL/dw\n",
        "            optimizer.step() # Градиентный спуск или его модификации (в данном случае Adam)\n",
        "            optimizer.zero_grad() # Зануление градиентов, чтобы их спокойно менять на следующей итерации\n",
        "            total_loss += loss.item()\n",
        "            if step % loss_every_nsteps == 0 and step != 0:\n",
        "                val_total_loss = 0\n",
        "                val_batch_count = 0\n",
        "                model.eval()\n",
        "                for _, val_batch in enumerate(BatchIterator(val_records, vocabulary, batch_size, bpe_processor, device=device)):\n",
        "                    logits = model(val_batch[\"inputs\"]) # Прямой проход\n",
        "                    val_total_loss += loss_function(logits, batch[\"outputs\"]) # Подсчёт ошибки\n",
        "                    val_batch_count += 1\n",
        "                avg_val_loss = val_total_loss/val_batch_count\n",
        "                print(\"Epoch = {}, Avg Train Loss = {:.4f}, Avg val loss = {:.4f}, Time = {:.2f}s\".format(epoch, total_loss / loss_every_nsteps, avg_val_loss, time.time() - start_time))\n",
        "                total_loss = 0\n",
        "                start_time = time.time()\n",
        "        total_loss = 0\n",
        "        start_time = time.time()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYmCkxqbxoW1",
        "colab_type": "code",
        "outputId": "3437468b-8a25-43f4-a3e2-bbf606a6527d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "\n",
        "from torch.nn.utils.rnn import pack_padded_sequence as pack\n",
        "from torch.nn.utils.rnn import pad_packed_sequence as unpack\n",
        "\n",
        "class SentenceEncoderRNN(nn.Module):\n",
        "    def __init__(self, input_size, embedding_dim, hidden_size, n_layers=3, dropout=0.3, bidirectional=True):\n",
        "        super(SentenceEncoderRNN, self).__init__()\n",
        "\n",
        "        num_directions = 2 if bidirectional else 1\n",
        "        assert hidden_size % num_directions == 0\n",
        "        hidden_size = hidden_size // num_directions\n",
        "\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.n_layers = n_layers\n",
        "        self.dropout = dropout\n",
        "        self.bidirectional = bidirectional\n",
        "\n",
        "        self.embedding_layer = nn.Embedding(input_size, embedding_dim)\n",
        "        self.rnn_layer = nn.LSTM(embedding_dim, hidden_size, n_layers, dropout=dropout, bidirectional=bidirectional, batch_first=True)\n",
        "        self.dropout_layer = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, inputs, hidden=None):\n",
        "        embedded = self.embedding_layer(inputs)\n",
        "        outputs, _ = self.rnn_layer(embedded, hidden)\n",
        "        sentences_embeddings = torch.mean(outputs, 1)\n",
        "        return sentences_embeddings\n",
        "\n",
        "class SentenceTaggerRNN(nn.Module):\n",
        "    def __init__(self,\n",
        "                 vocabulary_size,\n",
        "                 token_embedding_dim=256,\n",
        "                 sentence_encoder_hidden_size=256,\n",
        "                 hidden_size=256,\n",
        "                 bidirectional=True,\n",
        "                 sentence_encoder_n_layers=2,\n",
        "                 sentence_encoder_dropout=0.3,\n",
        "                 sentence_encoder_bidirectional=True,\n",
        "                 n_layers=1,\n",
        "                 dropout=0.3):\n",
        "        super(SentenceTaggerRNN, self).__init__()\n",
        "\n",
        "        num_directions = 2 if bidirectional else 1\n",
        "        assert hidden_size % num_directions == 0\n",
        "        hidden_size = hidden_size // num_directions\n",
        "\n",
        "        self.hidden_size = hidden_size\n",
        "        self.n_layers = n_layers\n",
        "        self.dropout = dropout\n",
        "        self.bidirectional = bidirectional\n",
        "\n",
        "        self.sentence_encoder = SentenceEncoderRNN(vocabulary_size, token_embedding_dim,\n",
        "                                                   sentence_encoder_hidden_size, sentence_encoder_n_layers, \n",
        "                                                   sentence_encoder_dropout, sentence_encoder_bidirectional)\n",
        "        self.rnn_layer = nn.LSTM(sentence_encoder_hidden_size, hidden_size, n_layers, dropout=dropout,\n",
        "                           bidirectional=bidirectional, batch_first=True)\n",
        "        self.dropout_layer = nn.Dropout(dropout)\n",
        "        self.content_linear_layer = nn.Linear(hidden_size * 2, 1)\n",
        "        self.document_linear_layer = nn.Linear(hidden_size * 2, hidden_size * 2)\n",
        "        self.salience_linear_layer = nn.Linear(hidden_size * 2, hidden_size * 2)\n",
        "        self.tanh_layer = nn.Tanh()\n",
        "\n",
        "    def forward(self, inputs, hidden=None):\n",
        "        batch_size = inputs.size(0)\n",
        "        sentences_count = inputs.size(1)\n",
        "        tokens_count = inputs.size(2)\n",
        "        inputs = inputs.reshape(-1, tokens_count)\n",
        "        embedded_sentences = self.sentence_encoder(inputs)\n",
        "        embedded_sentences = embedded_sentences.reshape(batch_size, sentences_count, -1)\n",
        "        outputs, _ = self.rnn_layer(embedded_sentences, hidden)\n",
        "        outputs = self.dropout_layer(outputs)\n",
        "        document_embedding = self.tanh_layer(self.document_linear_layer(torch.mean(outputs, 1)))\n",
        "        content = self.content_linear_layer(outputs).squeeze(2)\n",
        "        salience = torch.bmm(outputs, self.salience_linear_layer(document_embedding).unsqueeze(2)).squeeze(2)\n",
        "        return content + salience\n",
        "\n",
        "model = SentenceTaggerRNN(vocabulary.size())\n",
        "train_model(model, ext_train_records, ext_val_records, vocabulary, bpe_processor, device_name=\"cuda\", batch_size=32)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.3 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Trainable params: 5250305\n",
            "Epoch = 0, Avg Train Loss = 0.3309, Avg val loss = 0.2649, Time = 6.50s\n",
            "Epoch = 0, Avg Train Loss = 0.2509, Avg val loss = 0.2661, Time = 6.25s\n",
            "Epoch = 0, Avg Train Loss = 0.2351, Avg val loss = 0.2393, Time = 6.19s\n",
            "Epoch = 0, Avg Train Loss = 0.2416, Avg val loss = 0.2256, Time = 6.17s\n",
            "Epoch = 0, Avg Train Loss = 0.2331, Avg val loss = 0.2530, Time = 6.16s\n",
            "Epoch = 0, Avg Train Loss = 0.2335, Avg val loss = 0.2323, Time = 6.22s\n",
            "Epoch = 0, Avg Train Loss = 0.2426, Avg val loss = 0.2350, Time = 6.15s\n",
            "Epoch = 0, Avg Train Loss = 0.2270, Avg val loss = 0.2374, Time = 6.20s\n",
            "Epoch = 0, Avg Train Loss = 0.2299, Avg val loss = 0.2378, Time = 6.15s\n",
            "Epoch = 0, Avg Train Loss = 0.2345, Avg val loss = 0.2711, Time = 6.15s\n",
            "Epoch = 0, Avg Train Loss = 0.2309, Avg val loss = 0.2176, Time = 6.26s\n",
            "Epoch = 0, Avg Train Loss = 0.2332, Avg val loss = 0.2271, Time = 6.13s\n",
            "Epoch = 0, Avg Train Loss = 0.2252, Avg val loss = 0.2660, Time = 6.25s\n",
            "Epoch = 0, Avg Train Loss = 0.2348, Avg val loss = 0.2509, Time = 6.14s\n",
            "Epoch = 0, Avg Train Loss = 0.2310, Avg val loss = 0.2688, Time = 6.28s\n",
            "Epoch = 0, Avg Train Loss = 0.2278, Avg val loss = 0.2469, Time = 6.22s\n",
            "Epoch = 0, Avg Train Loss = 0.2289, Avg val loss = 0.2205, Time = 6.18s\n",
            "Epoch = 0, Avg Train Loss = 0.2283, Avg val loss = 0.2720, Time = 6.33s\n",
            "Epoch = 0, Avg Train Loss = 0.2273, Avg val loss = 0.2384, Time = 6.18s\n",
            "Epoch = 0, Avg Train Loss = 0.2273, Avg val loss = 0.2607, Time = 6.17s\n",
            "Epoch = 0, Avg Train Loss = 0.2302, Avg val loss = 0.2524, Time = 6.16s\n",
            "Epoch = 0, Avg Train Loss = 0.2314, Avg val loss = 0.2744, Time = 6.16s\n",
            "Epoch = 0, Avg Train Loss = 0.2308, Avg val loss = 0.2510, Time = 6.16s\n",
            "Epoch = 0, Avg Train Loss = 0.2219, Avg val loss = 0.2597, Time = 6.24s\n",
            "Epoch = 0, Avg Train Loss = 0.2317, Avg val loss = 0.2631, Time = 6.26s\n",
            "Epoch = 0, Avg Train Loss = 0.2229, Avg val loss = 0.2481, Time = 6.19s\n",
            "Epoch = 0, Avg Train Loss = 0.2325, Avg val loss = 0.2754, Time = 6.26s\n",
            "Epoch = 0, Avg Train Loss = 0.2267, Avg val loss = 0.2355, Time = 6.22s\n",
            "Epoch = 0, Avg Train Loss = 0.2220, Avg val loss = 0.2239, Time = 6.23s\n",
            "Epoch = 0, Avg Train Loss = 0.2268, Avg val loss = 0.2545, Time = 6.18s\n",
            "Epoch = 0, Avg Train Loss = 0.2290, Avg val loss = 0.2447, Time = 6.24s\n",
            "Epoch = 1, Avg Train Loss = 0.2389, Avg val loss = 0.2416, Time = 6.42s\n",
            "Epoch = 1, Avg Train Loss = 0.2196, Avg val loss = 0.2474, Time = 6.17s\n",
            "Epoch = 1, Avg Train Loss = 0.2105, Avg val loss = 0.2301, Time = 6.31s\n",
            "Epoch = 1, Avg Train Loss = 0.2214, Avg val loss = 0.2550, Time = 6.23s\n",
            "Epoch = 1, Avg Train Loss = 0.2186, Avg val loss = 0.2744, Time = 6.21s\n",
            "Epoch = 1, Avg Train Loss = 0.2253, Avg val loss = 0.3000, Time = 6.20s\n",
            "Epoch = 1, Avg Train Loss = 0.2207, Avg val loss = 0.2258, Time = 6.23s\n",
            "Epoch = 1, Avg Train Loss = 0.2204, Avg val loss = 0.2184, Time = 6.23s\n",
            "Epoch = 1, Avg Train Loss = 0.2205, Avg val loss = 0.2237, Time = 6.22s\n",
            "Epoch = 1, Avg Train Loss = 0.2237, Avg val loss = 0.2504, Time = 6.30s\n",
            "Epoch = 1, Avg Train Loss = 0.2248, Avg val loss = 0.2641, Time = 6.26s\n",
            "Epoch = 1, Avg Train Loss = 0.2178, Avg val loss = 0.2775, Time = 6.18s\n",
            "Epoch = 1, Avg Train Loss = 0.2183, Avg val loss = 0.2317, Time = 6.22s\n",
            "Epoch = 1, Avg Train Loss = 0.2210, Avg val loss = 0.2517, Time = 6.14s\n",
            "Epoch = 1, Avg Train Loss = 0.2160, Avg val loss = 0.2348, Time = 6.17s\n",
            "Epoch = 1, Avg Train Loss = 0.2140, Avg val loss = 0.2044, Time = 6.23s\n",
            "Epoch = 1, Avg Train Loss = 0.2124, Avg val loss = 0.2374, Time = 6.16s\n",
            "Epoch = 1, Avg Train Loss = 0.2124, Avg val loss = 0.2332, Time = 6.14s\n",
            "Epoch = 1, Avg Train Loss = 0.2159, Avg val loss = 0.2486, Time = 6.13s\n",
            "Epoch = 1, Avg Train Loss = 0.2267, Avg val loss = 0.2671, Time = 6.41s\n",
            "Epoch = 1, Avg Train Loss = 0.2171, Avg val loss = 0.2604, Time = 6.21s\n",
            "Epoch = 1, Avg Train Loss = 0.2177, Avg val loss = 0.2397, Time = 6.21s\n",
            "Epoch = 1, Avg Train Loss = 0.2180, Avg val loss = 0.2451, Time = 6.26s\n",
            "Epoch = 1, Avg Train Loss = 0.2148, Avg val loss = 0.2368, Time = 6.22s\n",
            "Epoch = 1, Avg Train Loss = 0.2130, Avg val loss = 0.2321, Time = 6.23s\n",
            "Epoch = 1, Avg Train Loss = 0.2185, Avg val loss = 0.2296, Time = 6.23s\n",
            "Epoch = 1, Avg Train Loss = 0.2065, Avg val loss = 0.2892, Time = 6.24s\n",
            "Epoch = 1, Avg Train Loss = 0.2143, Avg val loss = 0.2458, Time = 6.29s\n",
            "Epoch = 1, Avg Train Loss = 0.2231, Avg val loss = 0.2438, Time = 6.23s\n",
            "Epoch = 1, Avg Train Loss = 0.2213, Avg val loss = 0.2460, Time = 6.22s\n",
            "Epoch = 1, Avg Train Loss = 0.2270, Avg val loss = 0.2482, Time = 6.27s\n",
            "Epoch = 2, Avg Train Loss = 0.2160, Avg val loss = 0.2173, Time = 6.37s\n",
            "Epoch = 2, Avg Train Loss = 0.2006, Avg val loss = 0.2755, Time = 6.28s\n",
            "Epoch = 2, Avg Train Loss = 0.2017, Avg val loss = 0.2680, Time = 6.22s\n",
            "Epoch = 2, Avg Train Loss = 0.2043, Avg val loss = 0.2878, Time = 6.28s\n",
            "Epoch = 2, Avg Train Loss = 0.2031, Avg val loss = 0.2019, Time = 6.24s\n",
            "Epoch = 2, Avg Train Loss = 0.2163, Avg val loss = 0.2758, Time = 6.33s\n",
            "Epoch = 2, Avg Train Loss = 0.2063, Avg val loss = 0.2849, Time = 6.20s\n",
            "Epoch = 2, Avg Train Loss = 0.2041, Avg val loss = 0.2267, Time = 6.21s\n",
            "Epoch = 2, Avg Train Loss = 0.2130, Avg val loss = 0.2778, Time = 6.20s\n",
            "Epoch = 2, Avg Train Loss = 0.2128, Avg val loss = 0.2845, Time = 6.26s\n",
            "Epoch = 2, Avg Train Loss = 0.2065, Avg val loss = 0.2596, Time = 6.32s\n",
            "Epoch = 2, Avg Train Loss = 0.2105, Avg val loss = 0.3122, Time = 6.33s\n",
            "Epoch = 2, Avg Train Loss = 0.2028, Avg val loss = 0.2516, Time = 6.18s\n",
            "Epoch = 2, Avg Train Loss = 0.2033, Avg val loss = 0.2281, Time = 6.16s\n",
            "Epoch = 2, Avg Train Loss = 0.2034, Avg val loss = 0.2746, Time = 6.27s\n",
            "Epoch = 2, Avg Train Loss = 0.2064, Avg val loss = 0.2859, Time = 6.21s\n",
            "Epoch = 2, Avg Train Loss = 0.2013, Avg val loss = 0.2729, Time = 6.28s\n",
            "Epoch = 2, Avg Train Loss = 0.2172, Avg val loss = 0.2668, Time = 6.20s\n",
            "Epoch = 2, Avg Train Loss = 0.2129, Avg val loss = 0.2616, Time = 6.17s\n",
            "Epoch = 2, Avg Train Loss = 0.1986, Avg val loss = 0.2421, Time = 6.24s\n",
            "Epoch = 2, Avg Train Loss = 0.2071, Avg val loss = 0.2502, Time = 6.22s\n",
            "Epoch = 2, Avg Train Loss = 0.2102, Avg val loss = 0.2801, Time = 6.32s\n",
            "Epoch = 2, Avg Train Loss = 0.2087, Avg val loss = 0.2803, Time = 6.17s\n",
            "Epoch = 2, Avg Train Loss = 0.2152, Avg val loss = 0.3028, Time = 6.19s\n",
            "Epoch = 2, Avg Train Loss = 0.2072, Avg val loss = 0.2740, Time = 6.19s\n",
            "Epoch = 2, Avg Train Loss = 0.2071, Avg val loss = 0.2346, Time = 6.17s\n",
            "Epoch = 2, Avg Train Loss = 0.2012, Avg val loss = 0.2622, Time = 6.20s\n",
            "Epoch = 2, Avg Train Loss = 0.2072, Avg val loss = 0.2853, Time = 6.24s\n",
            "Epoch = 2, Avg Train Loss = 0.2142, Avg val loss = 0.2721, Time = 6.26s\n",
            "Epoch = 2, Avg Train Loss = 0.2090, Avg val loss = 0.2798, Time = 6.31s\n",
            "Epoch = 2, Avg Train Loss = 0.2102, Avg val loss = 0.2568, Time = 6.19s\n",
            "Epoch = 3, Avg Train Loss = 0.1990, Avg val loss = 0.2462, Time = 6.38s\n",
            "Epoch = 3, Avg Train Loss = 0.1795, Avg val loss = 0.3033, Time = 6.17s\n",
            "Epoch = 3, Avg Train Loss = 0.1844, Avg val loss = 0.2509, Time = 6.16s\n",
            "Epoch = 3, Avg Train Loss = 0.1830, Avg val loss = 0.2741, Time = 6.26s\n",
            "Epoch = 3, Avg Train Loss = 0.1897, Avg val loss = 0.2928, Time = 6.17s\n",
            "Epoch = 3, Avg Train Loss = 0.1803, Avg val loss = 0.2850, Time = 6.18s\n",
            "Epoch = 3, Avg Train Loss = 0.1869, Avg val loss = 0.3224, Time = 6.16s\n",
            "Epoch = 3, Avg Train Loss = 0.1890, Avg val loss = 0.2590, Time = 6.35s\n",
            "Epoch = 3, Avg Train Loss = 0.1900, Avg val loss = 0.3094, Time = 6.24s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-58-e15f0c5224ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSentenceTaggerRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mext_train_records\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mext_val_records\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbpe_processor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-57-c5b86b712972>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_records, val_records, vocabulary, bpe_processor, batch_size, epochs_count, loss_every_nsteps, lr, device_name)\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0mval_batch_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBatchIterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_records\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbpe_processor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m                     \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"inputs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Прямой проход\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m                     \u001b[0mval_total_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"outputs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Подсчёт ошибки\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-53-1c2a86606552>\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     57\u001b[0m                     \u001b[0msentences_indicies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"oracle_sentences\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m                 \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbpe_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbpe_processor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_sentence_length\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m                 \u001b[0mmax_sentence_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_sentence_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtokens\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences_indicies\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-53-1c2a86606552>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     57\u001b[0m                     \u001b[0msentences_indicies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"oracle_sentences\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m                 \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbpe_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbpe_processor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_sentence_length\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m                 \u001b[0mmax_sentence_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_sentence_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtokens\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences_indicies\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-48-7572b7d6e217>\u001b[0m in \u001b[0;36mbpe_tokenize\u001b[0;34m(text, bpe_processor)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mbpe_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbpe_processor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mbpe_processor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEncodeAsPieces\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mbpe_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"октябрь богат на изменения\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbpe_processor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EwqhK2dyKuGL",
        "colab_type": "code",
        "outputId": "bfab0e3d-6200-40e8-b71d-481bc2cacc02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "device = torch.device(\"cuda\")\n",
        "\n",
        "references = []\n",
        "predictions = []\n",
        "for step, batch in enumerate(BatchIterator(ext_test_records, vocabulary, 32, bpe_processor, device=device)):\n",
        "    logits = model(batch[\"inputs\"]) # Прямой проход\n",
        "    records = batch[\"records\"]\n",
        "    for record, record_logits in zip(records, logits):\n",
        "        sentences = record[\"sentences\"]\n",
        "        predicted_summary = []\n",
        "        for i, logit in enumerate(record_logits):\n",
        "            if logit > 0.0:\n",
        "                predicted_summary.append(sentences[i])\n",
        "        if not predicted_summary:\n",
        "            predicted_summary.append(sentences[torch.max(record_logits, dim=0)[1].item()])\n",
        "        predicted_summary = \" \".join(predicted_summary)\n",
        "        references.append(record[\"summary\"].lower())\n",
        "        predictions.append(predicted_summary)\n",
        "\n",
        "calc_scores(references, predictions)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Count: 1024\n",
            "Ref: восемь коротких рабочих недель ожидают россиян в 2020 году, подсчитал роструд. сразу после новогодних праздников первая трудовая неделя продлится всего два дня. власти не исключают в будущем переход страны на четырехдневную рабочую неделю. при условии высокой производительности труда.\n",
            "Hyp: при этом следующая майская неделя также будет сокращенной из-за выходных, приуроченных ко дню победы, добавил шкловец.\n",
            "BLEU:  0.20492005731883856\n",
            "ROUGE:  {'rouge-1': {'f': 0.20670073721820156, 'p': 0.3228627140233606, 'r': 0.163967760477759}, 'rouge-2': {'f': 0.08791812710854992, 'p': 0.13957926101621407, 'r': 0.07001153329401598}, 'rouge-l': {'f': 0.1564746913621876, 'p': 0.2906696446477151, 'r': 0.14713786844300072}}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZbnJMx3yOlAK",
        "colab_type": "text"
      },
      "source": [
        "### **Задание 2**\n",
        "Доделайте модель в соответствии с https://arxiv.org/pdf/1611.04230.pdf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Kc0etEGfJ0p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}